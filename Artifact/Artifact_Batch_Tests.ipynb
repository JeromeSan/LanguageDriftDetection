{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGCjq0of8uTC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from itertools import compress\n",
        "import random\n",
        "from random import sample\n",
        "import pickle\n",
        "import autosklearn.classification\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_recall_fscore_support\n",
        "import glob\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import openpyxl\n",
        "from skmultiflow.meta import AdaptiveRandomForestClassifier\n",
        "from skmultiflow.drift_detection import DDM, ADWIN, EDDM, HDDM_A, PageHinkley\n",
        "\n",
        "rng = np.random.default_rng(4711)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwrKxS6T2Sfh"
      },
      "source": [
        "# Data Prep for Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_vk2MpV9DU7",
        "outputId": "15c6a143-776a-4d23-ab21-2d9b9a29cb93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWC2H2jB9E6r"
      },
      "outputs": [],
      "source": [
        "commentsDF = pd.DataFrame(columns={'ID'})\n",
        "for file in glob.glob(\"/content/drive/MyDrive/MA/Daten/*\"):\n",
        "     tempDF = pd.read_excel(file)\n",
        "     commentsDF = pd.concat([commentsDF, tempDF], join='outer')\n",
        "\n",
        "commentsDF = commentsDF.drop(columns=['ID', 'Active', 'CID', 'Sperrhinweis', 'Loginname'],axis=1)\n",
        "\n",
        "commentsDF['Date'] =  pd.to_datetime(commentsDF['Date'], format='%Y-%m-%d %H:%M:%S')\n",
        "commentsDF['Time'] = pd.to_datetime(commentsDF['Date']).dt.time\n",
        "commentsDF['Date'] = pd.to_datetime(commentsDF['Date']).dt.date\n",
        "commentsDF['Date'] = pd.to_datetime(commentsDF['Date'], format='%Y-%m-%d')\n",
        "\n",
        "\n",
        "commentsDF['Text'] = commentsDF['Text'].astype(str)\n",
        "commentsDF['Title'] = commentsDF['Title'].astype(str)\n",
        "\n",
        "commentsDF = commentsDF.drop_duplicates(subset=['Text']) \n",
        "commentsDF = commentsDF.sort_values(by=['Date']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQxv7D7JHqXg"
      },
      "outputs": [],
      "source": [
        "# creates Sampled down version of dataset\n",
        "\n",
        "dateRange = pd.period_range(start='2018-11-01', end='2020-06-01', freq='M')\n",
        "timeSampledDF = pd.DataFrame(columns={'ID'})\n",
        "\n",
        "\n",
        "for i in range(len(dateRange)):\n",
        "  month = dateRange[i].month\n",
        "  year = dateRange[i].year\n",
        "  monthData = commentsDF[(commentsDF.Date.dt.month == dateRange[i].month) & (commentsDF.Date.dt.year == dateRange[i].year)]\n",
        "  countMinor = len(monthData[monthData.Abgelehnt == 1])\n",
        "  if countMinor < 600:\n",
        "    countMinor = 600\n",
        "  minorityDF = monthData[monthData.Abgelehnt == 1]\n",
        "  majorityDF = monthData[monthData.Abgelehnt == 0].sample(axis='index', \n",
        "                                                          n=countMinor, \n",
        "                                                          random_state=4711,)\n",
        "  timeSampledDF = pd.concat([timeSampledDF, majorityDF], join='outer')\n",
        "  timeSampledDF = pd.concat([timeSampledDF, minorityDF], join='outer')\n",
        "\n",
        "y_vals = commentsDF['Abgelehnt'].values\n",
        "y_vals = y_vals.astype(int)\n",
        "\n",
        "\n",
        "commentsDF['index1'] = commentsDF.index\n",
        "timeSampledDF['index1'] = timeSampledDF.index\n",
        "timeSampledDF.sort_values(by='Date',inplace=True)\n",
        "\n",
        "commentsDF['Mask'] = commentsDF.index1.apply(lambda x: 1 if x in timeSampledDF.index1 else 0)\n",
        "mask = np.array(commentsDF['Mask']).astype('bool')\n",
        "y_vals_sample = timeSampledDF['Abgelehnt'].values\n",
        "y_vals_sample = y_vals_sample.astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EWMA"
      ],
      "metadata": {
        "id": "7cbMeBEcRjZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXofqRnytfNX"
      },
      "outputs": [],
      "source": [
        "class EWMA():\n",
        "    \"\"\"The Exponentially Weighted Moving Average (EWMA) drift detection method class.\"\"\"\n",
        "    \n",
        "    def __init__(self, min_instance=30, lambda_=0.2, c=1, w=0.5):\n",
        "        '''\n",
        "        The Exponentially Weighted Moving Average (EWMA) drift detection method class.\n",
        "        :param: min_instance: quantity of instance to start detect a concept drift\n",
        "        '''\n",
        "\n",
        "        self.MINIMUM_NUM_INSTANCES = min_instance\n",
        "\n",
        "        self.t = 1.0\n",
        "        self.sum = 0.0\n",
        "        self.sigma_xt = 0.0\n",
        "        self.sigma_zt = 0.0\n",
        "        self.z_t = 0.0\n",
        "        self.lambda_ = lambda_\n",
        "        self.L_t = c\n",
        "        self.w = w\n",
        "        \n",
        "    def fit(self, classifier, vectorizer, W):\n",
        "        '''\n",
        "        method to fit to the current concept \n",
        "        '''\n",
        "        \n",
        "        for obs in W:\n",
        "            x, y = vectorizer.transform(obs[:-1]).toarray(), obs[-1]\n",
        "            \n",
        "            try:\n",
        "                yi = classifier.predict(x)\n",
        "            except:\n",
        "                yi = classifier.predict([x])\n",
        "            \n",
        "            pred = True\n",
        "            if(yi != y):\n",
        "                pred = False\n",
        "                \n",
        "            self.run(pred)\n",
        "    \n",
        "    def run(self, prediction):\n",
        "      '''\n",
        "      method to update the parameters of ewma\n",
        "      :param: prediction: true if the prediction is correct, otherwise no\n",
        "      '''\n",
        "      prediction = 1 if prediction is False else 0\n",
        "\n",
        "      warning_status = False\n",
        "      drift_status = False\n",
        "\n",
        "      # 1. UPDATING STATS\n",
        "      self.sum += prediction\n",
        "      self.sigma_xt = self.sum / self.t\n",
        "      self.sigma_zt = math.sqrt(self.sigma_xt * (1.0 - self.sigma_xt) * self.lambda_ * (1.0 - math.pow(1.0 - self.lambda_, 2.0 * self.t)) / (2.0 - self.lambda_))\n",
        "      self.t += 1\n",
        "\n",
        "      self.z_t += self.lambda_ * (prediction - self.z_t)\n",
        "      #L_t = 3.97 - 6.56 * self.sigma_xt + 48.73 * math.pow(self.sigma_xt, 3) - 330.13 * math.pow(self.sigma_xt, 5) + 848.18 * math.pow(self.sigma_xt, 7)\n",
        "\n",
        "      # 2. UPDATING WARNING AND DRIFT STATUSES\n",
        "      if self.t < self.MINIMUM_NUM_INSTANCES:\n",
        "        return False, False\n",
        "\n",
        "      if self.z_t > self.sigma_xt + self.L_t * self.sigma_zt:\n",
        "        drift_status = True\n",
        "      elif self.z_t > self.sigma_xt + self.w * self.L_t * self.sigma_zt:\n",
        "        warning_status = True\n",
        "\n",
        "      return warning_status, drift_status\n",
        "\n",
        "\n",
        "    def detect(self, y_true, y_pred):\n",
        "        '''\n",
        "        method to monitor the index\n",
        "        '''\n",
        "        \n",
        "        # checkint out the prediction of classifier\n",
        "        pred = True\n",
        "        if(y_true != y_pred):\n",
        "            pred = False\n",
        "        \n",
        "        warning_level, change_level = self.run(pred)\n",
        "        \n",
        "        return warning_level, change_level\n",
        "\n",
        "    def reset(self):\n",
        "        '''\n",
        "        method to reset the detector\n",
        "        '''\n",
        "        \n",
        "        self.t = 1\n",
        "        self.sum = 0\n",
        "        self.sigma_xt = 0\n",
        "        self.sigma_zt = 0\n",
        "        self.z_t = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2zR_0on2Wf3"
      },
      "source": [
        "# Artifact\n",
        "\n",
        "\n",
        "1.   Artifact with Classifier\n",
        "2.   Pure Detector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pfn3zu52RNJ"
      },
      "outputs": [],
      "source": [
        "class Artifact():\n",
        "\n",
        "  def __init__(self, training_data, model, batch_size = 500):\n",
        "    self.eddm = EDDM()\n",
        "    self.hddm = HDDM_A()\n",
        "    self.training_data = training_data\n",
        "    self.model = model\n",
        "    self.training_size = len(training_data)\n",
        "    self.corpus_save_DataFrame = pd.DataFrame()\n",
        "    self.inner_PWI = None\n",
        "    self.general_corpus = None\n",
        "    self.data_buffer = training_data\n",
        "    self.batch_size = batch_size\n",
        "    self.batch_len = 0 \n",
        "    self.test_corpora = 2\n",
        "    self.change_detected = False\n",
        "\n",
        "    # vectorizer definition\n",
        "    german_stop_words_import = open (\"/content/drive/MyDrive/MA/stopwords-de.csv\", \n",
        "                                 \"r\", encoding=\"utf-8\")\n",
        "    german_stop_words = pd.read_csv(german_stop_words_import, \n",
        "                                names=['stopwords'])['stopwords'].to_list()\n",
        "    self.vectorizer = TfidfVectorizer(stop_words=german_stop_words, \n",
        "                             ngram_range=(1,2), max_features=3000)\n",
        "    self.vectorizer = self.vectorizer.fit(training_data.Text)\n",
        "    \n",
        "    self.set_training_corpus(training_data)\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "    if isinstance(x, str):\n",
        "      x = vectorizer.transform([x]).toarray()\n",
        "\n",
        "    return self.model.predict(x)[0]\n",
        "\n",
        "  def add_data(self, x, y):\n",
        "    input = pd.DataFrame(data={'Text':[x], 'Abgelehnt':[y]})\n",
        "    self.data_buffer = pd.concat([self.data_buffer, input], ignore_index=True)\n",
        "    self.batch_len += 1\n",
        "    y_pred = self.predict(x)\n",
        "    error = abs(y_pred - y)\n",
        "    adwinError = abs(abs(y_pred-y)-1)\n",
        "\n",
        "    self.eddm.add_element(error)\n",
        "    self.hddm.add_element(error)\n",
        "\n",
        "    if (self.change_detected == False) & ((self.eddm.detected_change() or self.hddm.detected_change())):\n",
        "      self.change_detected = True\n",
        "\n",
        "\n",
        "    if (self.batch_len >= self.batch_size) & (self.change_detected == True):\n",
        "      print('Refitting a batch of size ', self.batch_len)\n",
        "      #test attempt without WI\n",
        "      # training_size = len(self.training_data)\n",
        "      # self.training_data = pd.concat([self.training_data, self.data_buffer])[:-training_size]\n",
        "      # print(self.training_data)\n",
        "      self.set_training_corpus(self.data_buffer)\n",
        "      self.data_buffer = self.training_data\n",
        "      x_train = self.vectorizer.fit_transform(self.training_data.Text).toarray()\n",
        "      self.model.reset()\n",
        "      self.model.partial_fit(x_train, self.training_data.Abgelehnt, [0,1])\n",
        "      self.batch_len = 0\n",
        "      self.change_detected = False\n",
        "\n",
        "    \n",
        "  #  sets the general corpus for the WI and calculates Inner WI for thresholding\n",
        "  def set_training_corpus(self, corpus):\n",
        "    \n",
        "    # intital setting of base corpus and PWI\n",
        "    if self.corpus_save_DataFrame.empty:\n",
        "      self.corpus_save_DataFrame = corpus\n",
        "      self.test_corpora = int(len(self.corpus_save_DataFrame)/self.batch_size)\n",
        "      self.general_corpus = self.splitPivotText(corpus)\n",
        "      self.inner_PWI = self.calcPWI(corpus)\n",
        "\n",
        "\n",
        "    # updating base corpus with new training data\n",
        "    else:\n",
        "      if self.test_corpora <= 1:\n",
        "        self.test_corpora = 2 \n",
        "\n",
        "      # adding new Corpus to Base Corpus to create Baseline\n",
        "      # if the new data set is closer to the dictionary than the existing one no new data will be added to the training set to avoid overfitting\n",
        "      compare_PWI = self.calcPWI(pd.concat([self.corpus_save_DataFrame, corpus]))\n",
        "      if compare_PWI > self.inner_PWI:\n",
        "        self.inner_PWI = compare_PWI\n",
        "      samples = np.array_split(self.corpus_save_DataFrame.sample(frac=1), self.test_corpora)\n",
        "\n",
        "      for sample in samples:\n",
        "        sample_corpus = pd.concat([sample, corpus])\n",
        "        test_corpus = self.splitPivotText(sample_corpus)\n",
        "\n",
        "        test_PWI = self.calcPWI(sample)\n",
        "\n",
        "        if test_PWI < self.inner_PWI:\n",
        "          print('New General Corpus set. Inner PWI at: ', test_PWI)\n",
        "          self.general_corpus = test_corpus\n",
        "          self.training_data = sample.reset_index(drop=True)\n",
        "          self.inner_PWI = test_PWI\n",
        "\n",
        "  def calcPWI(self, corpus):\n",
        "    general_Corpus, specialized_Corpus = train_test_split(corpus, test_size=0.5, random_state=4711) \n",
        "    pwi_frame = self.calcPWIFrame(self.splitPivotText(general_Corpus), self.splitPivotText(specialized_Corpus))\n",
        "    pwi = pwi_frame.WI_Time.sum() / pwi_frame.WI_Time.count()\n",
        "\n",
        "    return pwi\n",
        "\n",
        "  def splitPivotText(self, df):\n",
        "    functionDF =  df.copy()\n",
        "    functionDF['Text'] = functionDF['Text'].astype(str)\n",
        "    functionDF['Text'] = functionDF['Text'].apply(lambda x: x.split())\n",
        "    splitFrame = pd.DataFrame(functionDF['Text'].to_list())\n",
        "    splitFrame['Label'] = functionDF.reset_index().Abgelehnt\n",
        "\n",
        "    # create one column with every word and their occurence with labels\n",
        "    vocab = splitFrame.melt(id_vars='Label').drop(columns=['variable'])\n",
        "    # turns the label column into two separate columns and aggregates them\n",
        "    vocab['Removed'] = np.where(vocab['Label'] == 1, 1,0)\n",
        "    vocab['not_Removed'] = np.where(vocab['Label'] == np.nan, 0,1)\n",
        "    vocab = vocab.drop(columns=['Label'])\n",
        "\n",
        "    vocab['Removed'] = vocab.groupby('value')['Removed'].transform('sum')\n",
        "    vocab['not_Removed'] = vocab.groupby('value')['not_Removed'].transform('sum')\n",
        "    returnDF = vocab.drop_duplicates(subset=['value'])\n",
        "\n",
        "    returnDF = returnDF[returnDF['value'].notnull()]\n",
        "\n",
        "    return returnDF\n",
        "\n",
        "\n",
        "\n",
        "  def calcPWIFrame(self, generalCorpus, specializedCorpus):\n",
        "\n",
        "    mergedPivot = specializedCorpus.set_index('value').join(generalCorpus.set_index('value'), how='left', lsuffix='_specialized', rsuffix='_corpus').fillna(0).reset_index()\n",
        "    ts_time = specializedCorpus.Removed.sum() + specializedCorpus.not_Removed.sum()\n",
        "    tg_time = generalCorpus.Removed.sum() + generalCorpus.Removed.sum()  \n",
        "\n",
        "\n",
        "    mergedPivot['WI_Time'] = mergedPivot.apply(lambda x: self.calculate_polarized_pwi(x['Removed_specialized'] + x['not_Removed_specialized'], x['Removed_corpus'] + x['not_Removed_corpus'], ts_time, tg_time),axis=1)\n",
        "    \n",
        "    return mergedPivot\n",
        "\n",
        " \n",
        " \n",
        "  def calculate_polarized_pwi(self, ws, wg, ts, tg):\n",
        "\n",
        "    if((ws > 0) & (wg > 0)):  \n",
        "      pwi = (ws/ts)/(wg/tg)\n",
        "\n",
        "    elif(ws > 0):\n",
        "      pwi = ws/ts\n",
        "\n",
        "    elif(wg > 0):\n",
        "      pwi = ws / (wg/tg)\n",
        "\n",
        "    else:\n",
        "      pwi = 0\n",
        "\n",
        "    if np.isnan(pwi):\n",
        "      pwi = 0\n",
        "\n",
        "    return pwi"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzymxS4qRoR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EWMA Artifact"
      ],
      "metadata": {
        "id": "y_nYzFCqIBsI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs0jGGdQuQlE"
      },
      "outputs": [],
      "source": [
        "class ArtifactEWMA():\n",
        "\n",
        "  def __init__(self, training_data, model, batch_size = 500):\n",
        "    self.eddm = EDDM()\n",
        "    self.ewma = EWMA()\n",
        "    self.training_data = training_data\n",
        "    self.model = model\n",
        "    self.training_size = len(training_data)\n",
        "    self.corpus_save_DataFrame = pd.DataFrame()\n",
        "    self.inner_PWI = None\n",
        "    self.general_corpus = None\n",
        "    self.data_buffer = training_data\n",
        "    self.batch_size = batch_size\n",
        "    self.batch_len = 0 \n",
        "\n",
        "\n",
        "    # vectorizer definition\n",
        "    german_stop_words_import = open (\"/content/drive/MyDrive/MA/stopwords-de.csv\", \n",
        "                                 \"r\", encoding=\"utf-8\")\n",
        "    german_stop_words = pd.read_csv(german_stop_words_import, \n",
        "                                names=['stopwords'])['stopwords'].to_list()\n",
        "    self.vectorizer = TfidfVectorizer(stop_words=german_stop_words, \n",
        "                             ngram_range=(1,2), max_features=3000)\n",
        "    self.vectorizer = self.vectorizer.fit(training_data.Text)\n",
        "    \n",
        "    self.set_training_corpus(training_data)\n",
        "    self.ewma.fit(self.model, self.vectorizer, training_data.to_numpy())\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "    if isinstance(x, str):\n",
        "      x = vectorizer.transform([x]).toarray()\n",
        "\n",
        "    return self.model.predict(x)[0]\n",
        "\n",
        "  def add_data(self, x, y):\n",
        "    input = pd.DataFrame(data={'Text':[x], 'Abgelehnt':[y]})\n",
        "    self.data_buffer = pd.concat([self.data_buffer, input], ignore_index=True)\n",
        "    self.batch_len += 1\n",
        "    y_pred = self.predict(x)\n",
        "    error = abs(y_pred - y)\n",
        "    adwinError = abs(abs(y_pred-y)-1)\n",
        "\n",
        "    self.eddm.add_element(error)\n",
        "    warning_level, change_level = self.ewma.run(error)\n",
        "\n",
        "    # self.ph.add_element(error)\n",
        "\n",
        "    if (self.batch_len >= self.batch_size) & ((self.eddm.detected_change() or (change_level == True))):\n",
        "      print('Refitting a batch of size ', self.batch_len)\n",
        "      # print(self.data_buffer)\n",
        "      training_size = len(self.training_data)\n",
        "      self.training_data = pd.concat([self.training_data, self.data_buffer])[:-training_size]\n",
        "      # self.set_training_corpus(self.data_buffer)\n",
        "      # self.data_buffer = self.training_data\n",
        "      x_train = self.vectorizer.fit_transform(self.training_data.Text).toarray()\n",
        "      # self.model.reset()\n",
        "      self.model.fit(x_train, self.training_data.Abgelehnt, [0,1])\n",
        "      self.batch_len = 0\n",
        "\n",
        "    \n",
        "  #  sets the general corpus for the WI and calculates Inner WI for thresholding\n",
        "  def set_training_corpus(self, corpus):\n",
        "    \n",
        "    # intital setting of base corpus and PWI\n",
        "    if self.corpus_save_DataFrame.empty:\n",
        "      self.corpus_save_DataFrame = corpus\n",
        "      general_Corpus_sample, specialized_Corpus_sample = train_test_split(corpus, test_size=0.5, random_state=4711)\n",
        "\n",
        "      self.general_corpus = self.splitPivotText(corpus)\n",
        "      general_PWI = self.calcPWIFrame(self.splitPivotText(general_Corpus_sample), self.splitPivotText(specialized_Corpus_sample))\n",
        "      self.inner_PWI = general_PWI.WI_Time.sum() / general_PWI.WI_Time.count()\n",
        "\n",
        "\n",
        "    # updating base corpus with new training data\n",
        "    else:\n",
        "      test_corpora = int(len(self.corpus_save_DataFrame)/self.batch_size)\n",
        "      if self.test_corpora <= 1:\n",
        "        self.test_corpora = 2 \n",
        "      # print('Save Frame and Corpus', self.corpus_save_DataFrame, corpus)\n",
        "      samples = np.array_split(self.corpus_save_DataFrame.sample(frac=1), self.test_corpora)\n",
        "\n",
        "      for sample in samples:\n",
        "        sample_corpus = pd.concat([self.sample, corpus])\n",
        "        test_corpus = self.splitPivotText(sample_corpus)\n",
        "        general_Corpus_sample, specialized_Corpus_sample = train_test_split(sample, test_size=0.5, random_state=4711)\n",
        "        general_PWI = self.calcPWIFrame(self.splitPivotText(general_Corpus_sample), self.splitPivotText(specialized_Corpus_sample))\n",
        "\n",
        "        test_PWI =  general_PWI.WI_Time.sum() / general_PWI.WI_Time.count()\n",
        "\n",
        "        if test_PWI < self.inner_PWI:\n",
        "          print('New General Corpus set. Inner PWI at: ', test_PWI)\n",
        "          print(sample)\n",
        "          self.general_corpus = test_corpus\n",
        "          self.training_data = sample.reset_index(drop=True)\n",
        "          self.inner_PWI = test_PWI\n",
        "\n",
        "\n",
        "\n",
        "  def splitPivotText(self, df):\n",
        "    functionDF =  df.copy()\n",
        "    functionDF['Text'] = functionDF['Text'].astype(str)\n",
        "    functionDF['Text'] = functionDF['Text'].apply(lambda x: x.split())\n",
        "    splitFrame = pd.DataFrame(functionDF['Text'].to_list())\n",
        "    splitFrame['Label'] = functionDF.reset_index().Abgelehnt\n",
        "\n",
        "    # create one column with every word and their occurence with labels\n",
        "    vocab = splitFrame.melt(id_vars='Label').drop(columns=['variable'])\n",
        "    # turns the label column into two separate columns and aggregates them\n",
        "    vocab['Removed'] = np.where(vocab['Label'] == 1, 1,0)\n",
        "    vocab['not_Removed'] = np.where(vocab['Label'] == np.nan, 0,1)\n",
        "    vocab = vocab.drop(columns=['Label'])\n",
        "\n",
        "    vocab['Removed'] = vocab.groupby('value')['Removed'].transform('sum')\n",
        "    vocab['not_Removed'] = vocab.groupby('value')['not_Removed'].transform('sum')\n",
        "    returnDF = vocab.drop_duplicates(subset=['value'])\n",
        "\n",
        "    returnDF = returnDF[returnDF['value'].notnull()]\n",
        "\n",
        "    return returnDF\n",
        "\n",
        "\n",
        "\n",
        "  def calcPWIFrame(self, generalCorpus, specializedCorpus):\n",
        "\n",
        "    mergedPivot = specializedCorpus.set_index('value').join(generalCorpus.set_index('value'), how='left', lsuffix='_specialized', rsuffix='_corpus').fillna(0).reset_index()\n",
        "    ts_time = specializedCorpus.Removed.sum() + specializedCorpus.not_Removed.sum()\n",
        "    tg_time = generalCorpus.Removed.sum() + generalCorpus.Removed.sum()  \n",
        "\n",
        "\n",
        "    mergedPivot['WI_Time'] = mergedPivot.apply(lambda x: self.calculate_polarized_pwi(x['Removed_specialized'] + x['not_Removed_specialized'], x['Removed_corpus'] + x['not_Removed_corpus'], ts_time, tg_time),axis=1)\n",
        "    \n",
        "    return mergedPivot\n",
        "\n",
        " \n",
        " \n",
        "  def calculate_polarized_pwi(self, ws, wg, ts, tg):\n",
        "\n",
        "    if((ws > 0) & (wg > 0)):  \n",
        "      pwi = (ws/ts)/(wg/tg)\n",
        "\n",
        "    elif(ws > 0):\n",
        "      pwi = ws/ts\n",
        "\n",
        "    elif(wg > 0):\n",
        "      pwi = ws / (wg/tg)\n",
        "\n",
        "    else:\n",
        "      pwi = 0\n",
        "\n",
        "    if np.isnan(pwi):\n",
        "      pwi = 0\n",
        "\n",
        "    return pwi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCpdo5VLYvCh"
      },
      "outputs": [],
      "source": [
        "class detectorEnsemble():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.eddm = EDDM()\n",
        "    self.adwin = ADWIN()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IetoqAnXdpfg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "8mdAxHoRID5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHZrD5iXdmCt"
      },
      "outputs": [],
      "source": [
        "tfidf_pickle = open (\"/LanguageDriftDetection/Data/Preprocessing/preprocessed_balanced.pk\", \"rb\")\n",
        "preprocessed = pickle.load(tfidf_pickle)\n",
        "\n",
        "train_batch = np.array(timeSampledDF.Date < \"2019-06-01\")\n",
        "test = timeSampledDF['Date'] >= \"2019-06-01\"\n",
        "\n",
        "\n",
        "german_stop_words_import = open (\"/LanguageDriftDetection/Data/Stopwords/stopwords-de.csv\", \n",
        "                                 \"r\", encoding=\"utf-8\")\n",
        "german_stop_words = pd.read_csv(german_stop_words_import, \n",
        "                                names=['stopwords'])['stopwords'].to_list()\n",
        "vectorizer = TfidfVectorizer(stop_words=german_stop_words, \n",
        "                             ngram_range=(1,2), max_features=3000)\n",
        "\n",
        "x_timed = list(compress(preprocessed, train_batch))\n",
        "\n",
        "y_train_timed = y_vals_sample[train_batch]\n",
        "x_train_timed = vectorizer.fit_transform(x_timed).toarray()\n",
        "\n",
        "trainMask_3m = (timeSampledDF.Date < \"2019-06-01\") & (timeSampledDF.Date >= \"2019-05-01\")\n",
        "x_3m = list(compress(preprocessed, trainMask_3m))\n",
        "\n",
        "x_train_3m = vectorizer.fit_transform(x_3m).toarray()\n",
        "y_train_3m = y_vals_sample[trainMask_3m]\n",
        "\n",
        "timeSampledDF.Text = preprocessed\n",
        "training_data = timeSampledDF[trainMask_3m].reset_index(drop=True).loc[:,['Text', 'Abgelehnt']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpH18TTVcUYU",
        "outputId": "0886e623-df7e-4327-bd11-add2de24f3ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaptiveRandomForestClassifier(binary_split=False, disable_weighted_vote=False,\n",
              "                               drift_detection_method=None, grace_period=50,\n",
              "                               lambda_value=6, leaf_prediction='nba',\n",
              "                               max_byte_size=33554432, max_features=55,\n",
              "                               memory_estimate_period=2000000, n_estimators=10,\n",
              "                               nb_threshold=0, no_preprune=False,\n",
              "                               nominal_attributes=None,\n",
              "                               performance_metric='acc', random_state=None,\n",
              "                               remove_poor_atts=False, split_confidence=0.01,\n",
              "                               split_criterion='info_gain',\n",
              "                               stop_mem_management=False, tie_threshold=0.05,\n",
              "                               warning_detection_method=None)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model = AdaptiveRandomForestClassifier(drift_detection_method = None, warning_detection_method= None)\n",
        "model.fit(x_train_3m, y_train_3m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC9f-yHUc0vl"
      },
      "outputs": [],
      "source": [
        "# model tests per month\n",
        "def testMonthly(df, y_vals) : \n",
        "\n",
        "  testMonths = pd.to_datetime(['06-19', '07-19', '08-19', '09-19', '10-19','11-19','12-19','01-20', '02-20','03-20','04-20','05-20','06-20'],\n",
        "                            format='%m-%y')\n",
        "\n",
        "  # df.sort_values(by='Date')\n",
        "  output = pd.DataFrame()\n",
        "  for i in range(len(testMonths)):\n",
        "    monthMask = (df.Date.dt.month == testMonths[i].month) & (df.Date.dt.year == testMonths[i].year)\n",
        "    y_test = y_vals[monthMask]\n",
        "    y_pred = df.y_pred[monthMask]\n",
        "    scores = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")\n",
        "    roc_score = roc_auc_score(y_test,y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred) \n",
        "\n",
        "    resultDF = pd.DataFrame({'ROC-AUC': [roc_score], 'Precision': [scores[0]],\n",
        "                           'Recall': [scores[1]], 'F1-Score': [scores[2]],\n",
        "                           'Accuracy': accuracy})\n",
        "    output = output.append(resultDF)\n",
        "  # print('Results for {}: \\n'.format(testMonths[i].strftime(\"%b %y\")), results)\n",
        "  output.index= testMonths\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdNP98eccW5L",
        "outputId": "83b75053-d3d2-440b-ec59-7e8b9766cbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ROC-AUC  Precision    Recall  F1-Score  Accuracy\n",
              "2019-06-01  0.488625   0.475401  0.488625  0.409229  0.488625\n",
              "2019-07-01  0.486230   0.483535  0.486230  0.464311  0.486230\n",
              "2019-08-01  0.475155   0.442413  0.475155  0.388191  0.475155\n",
              "2019-09-01  0.490345   0.475412  0.490345  0.399111  0.490345\n",
              "2019-10-01  0.486486   0.415829  0.486486  0.350096  0.486486\n",
              "2019-11-01  0.513480   0.515460  0.513480  0.497390  0.513480\n",
              "2019-12-01  0.518092   0.520143  0.518092  0.505506  0.518092\n",
              "2020-01-01  0.509053   0.511144  0.509053  0.484892  0.509053\n",
              "2020-02-01  0.540816   0.559442  0.540816  0.501789  0.540816\n",
              "2020-03-01  0.547112   0.607967  0.547112  0.472829  0.547112\n",
              "2020-04-01  0.498073   0.498152  0.498073  0.494001  0.500502\n",
              "2020-05-01  0.526184   0.531891  0.526184  0.519744  0.577551\n",
              "2020-06-01  0.512173   0.509438  0.512173  0.482258  0.513514"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fb58696-efdc-484a-824a-9bf0b869b204\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROC-AUC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-06-01</th>\n",
              "      <td>0.488625</td>\n",
              "      <td>0.475401</td>\n",
              "      <td>0.488625</td>\n",
              "      <td>0.409229</td>\n",
              "      <td>0.488625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01</th>\n",
              "      <td>0.486230</td>\n",
              "      <td>0.483535</td>\n",
              "      <td>0.486230</td>\n",
              "      <td>0.464311</td>\n",
              "      <td>0.486230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>0.475155</td>\n",
              "      <td>0.442413</td>\n",
              "      <td>0.475155</td>\n",
              "      <td>0.388191</td>\n",
              "      <td>0.475155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-01</th>\n",
              "      <td>0.490345</td>\n",
              "      <td>0.475412</td>\n",
              "      <td>0.490345</td>\n",
              "      <td>0.399111</td>\n",
              "      <td>0.490345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-01</th>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.415829</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.350096</td>\n",
              "      <td>0.486486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-01</th>\n",
              "      <td>0.513480</td>\n",
              "      <td>0.515460</td>\n",
              "      <td>0.513480</td>\n",
              "      <td>0.497390</td>\n",
              "      <td>0.513480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-01</th>\n",
              "      <td>0.518092</td>\n",
              "      <td>0.520143</td>\n",
              "      <td>0.518092</td>\n",
              "      <td>0.505506</td>\n",
              "      <td>0.518092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-01</th>\n",
              "      <td>0.509053</td>\n",
              "      <td>0.511144</td>\n",
              "      <td>0.509053</td>\n",
              "      <td>0.484892</td>\n",
              "      <td>0.509053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01</th>\n",
              "      <td>0.540816</td>\n",
              "      <td>0.559442</td>\n",
              "      <td>0.540816</td>\n",
              "      <td>0.501789</td>\n",
              "      <td>0.540816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01</th>\n",
              "      <td>0.547112</td>\n",
              "      <td>0.607967</td>\n",
              "      <td>0.547112</td>\n",
              "      <td>0.472829</td>\n",
              "      <td>0.547112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-01</th>\n",
              "      <td>0.498073</td>\n",
              "      <td>0.498152</td>\n",
              "      <td>0.498073</td>\n",
              "      <td>0.494001</td>\n",
              "      <td>0.500502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-01</th>\n",
              "      <td>0.526184</td>\n",
              "      <td>0.531891</td>\n",
              "      <td>0.526184</td>\n",
              "      <td>0.519744</td>\n",
              "      <td>0.577551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-01</th>\n",
              "      <td>0.512173</td>\n",
              "      <td>0.509438</td>\n",
              "      <td>0.512173</td>\n",
              "      <td>0.482258</td>\n",
              "      <td>0.513514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fb58696-efdc-484a-824a-9bf0b869b204')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fb58696-efdc-484a-824a-9bf0b869b204 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fb58696-efdc-484a-824a-9bf0b869b204');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "results = timeSampledDF[test]\n",
        "results['y_pred'] = fullPred\n",
        "testMonthly(results, results.Abgelehnt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 100\n"
      ],
      "metadata": {
        "id": "LERSAE4_x1oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact = Artifact(training_data, model, 100)\n",
        "test_data = timeSampledDF[test].reset_index(drop=True)\n",
        "fullPred = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  fullPred.append(artifact.predict(test_data.loc[i, 'Text']))\n",
        "  artifact.add_data(test_data.loc[i, 'Text'], test_data.loc[i, 'Abgelehnt'])\n",
        "\n",
        "results = timeSampledDF[test]\n",
        "results['y_pred'] = fullPred\n",
        "testMonthly(results, results.Abgelehnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ewmtv1fOx28V",
        "outputId": "1dc04005-d6d7-42d9-ae54-eb9be97dd580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16446290070544023\n",
            "New General Corpus set. Inner PWI at:  0.07796179820764992\n",
            "Refitting a batch of size  261\n",
            "New General Corpus set. Inner PWI at:  0.11613262907546207\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.22680285529630628\n",
            "New General Corpus set. Inner PWI at:  0.17268482687925504\n",
            "New General Corpus set. Inner PWI at:  0.16261169536146164\n",
            "New General Corpus set. Inner PWI at:  0.13949853722235087\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.25167102633815236\n",
            "New General Corpus set. Inner PWI at:  0.1730536101973259\n",
            "New General Corpus set. Inner PWI at:  0.16967672122569438\n",
            "New General Corpus set. Inner PWI at:  0.16646316941934033\n",
            "New General Corpus set. Inner PWI at:  0.14281932432856845\n",
            "New General Corpus set. Inner PWI at:  0.11013645838938681\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.370591692124549\n",
            "New General Corpus set. Inner PWI at:  0.30798758117561154\n",
            "New General Corpus set. Inner PWI at:  0.21905827365248923\n",
            "New General Corpus set. Inner PWI at:  0.1275088427991952\n",
            "Refitting a batch of size  160\n",
            "New General Corpus set. Inner PWI at:  0.21889668930694853\n",
            "New General Corpus set. Inner PWI at:  0.2032593884471468\n",
            "New General Corpus set. Inner PWI at:  0.1650204531725143\n",
            "New General Corpus set. Inner PWI at:  0.16042815114153977\n",
            "New General Corpus set. Inner PWI at:  0.09173696873212421\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1466516418479108\n",
            "New General Corpus set. Inner PWI at:  0.12066453018795319\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.24944447094652536\n",
            "New General Corpus set. Inner PWI at:  0.19994334761493063\n",
            "New General Corpus set. Inner PWI at:  0.18104327260094316\n",
            "New General Corpus set. Inner PWI at:  0.17400384521265114\n",
            "New General Corpus set. Inner PWI at:  0.13425172087647394\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17586860864239212\n",
            "New General Corpus set. Inner PWI at:  0.13808104249931044\n",
            "New General Corpus set. Inner PWI at:  0.11755725889918749\n",
            "New General Corpus set. Inner PWI at:  0.10655430827743513\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20456299929957877\n",
            "New General Corpus set. Inner PWI at:  0.16278950510342444\n",
            "New General Corpus set. Inner PWI at:  0.11579295945322626\n",
            "New General Corpus set. Inner PWI at:  0.10903552294446599\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2924182535767825\n",
            "New General Corpus set. Inner PWI at:  0.25517936732808155\n",
            "New General Corpus set. Inner PWI at:  0.2450393960913112\n",
            "New General Corpus set. Inner PWI at:  0.1773268988375437\n",
            "New General Corpus set. Inner PWI at:  0.16606820700097094\n",
            "New General Corpus set. Inner PWI at:  0.15109267161703901\n",
            "New General Corpus set. Inner PWI at:  0.14939909855204817\n",
            "New General Corpus set. Inner PWI at:  0.12312665873424453\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.19171276058156242\n",
            "New General Corpus set. Inner PWI at:  0.14238226587977484\n",
            "New General Corpus set. Inner PWI at:  0.13716841777920188\n",
            "New General Corpus set. Inner PWI at:  0.10041030966650287\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1971657973712016\n",
            "New General Corpus set. Inner PWI at:  0.15404154519834212\n",
            "New General Corpus set. Inner PWI at:  0.14763617942716564\n",
            "New General Corpus set. Inner PWI at:  0.12210630179473786\n",
            "New General Corpus set. Inner PWI at:  0.11747656177627291\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2337565716411059\n",
            "New General Corpus set. Inner PWI at:  0.1516088434240894\n",
            "New General Corpus set. Inner PWI at:  0.14846386696226765\n",
            "New General Corpus set. Inner PWI at:  0.14692555776874994\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17594086165126444\n",
            "New General Corpus set. Inner PWI at:  0.16704397723246817\n",
            "New General Corpus set. Inner PWI at:  0.14410943882616203\n",
            "New General Corpus set. Inner PWI at:  0.10871615556404728\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.36390151162910167\n",
            "New General Corpus set. Inner PWI at:  0.1785978583418162\n",
            "New General Corpus set. Inner PWI at:  0.16605929252540852\n",
            "New General Corpus set. Inner PWI at:  0.16070408390879132\n",
            "New General Corpus set. Inner PWI at:  0.14224769075559784\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16331030625884624\n",
            "New General Corpus set. Inner PWI at:  0.1604524907094883\n",
            "New General Corpus set. Inner PWI at:  0.1501625083562336\n",
            "New General Corpus set. Inner PWI at:  0.14803104969701383\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1592184243259212\n",
            "New General Corpus set. Inner PWI at:  0.14305593276736722\n",
            "New General Corpus set. Inner PWI at:  0.0897163661635251\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.23604071386438236\n",
            "New General Corpus set. Inner PWI at:  0.20194446906846014\n",
            "New General Corpus set. Inner PWI at:  0.15769557257873262\n",
            "New General Corpus set. Inner PWI at:  0.14672079472364702\n",
            "New General Corpus set. Inner PWI at:  0.14658449293028952\n",
            "New General Corpus set. Inner PWI at:  0.13140074252371667\n",
            "New General Corpus set. Inner PWI at:  0.12445214745629202\n",
            "New General Corpus set. Inner PWI at:  0.10412658807258494\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3376047854166118\n",
            "New General Corpus set. Inner PWI at:  0.21572251600352893\n",
            "New General Corpus set. Inner PWI at:  0.2146173243744516\n",
            "New General Corpus set. Inner PWI at:  0.15040317075739637\n",
            "New General Corpus set. Inner PWI at:  0.1244428340066692\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20433281279201398\n",
            "New General Corpus set. Inner PWI at:  0.1578245779263374\n",
            "New General Corpus set. Inner PWI at:  0.14150625145457005\n",
            "New General Corpus set. Inner PWI at:  0.10208293934116507\n",
            "New General Corpus set. Inner PWI at:  0.10122331578904593\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1768295480049378\n",
            "New General Corpus set. Inner PWI at:  0.1754601014605301\n",
            "New General Corpus set. Inner PWI at:  0.1714485011982871\n",
            "New General Corpus set. Inner PWI at:  0.13955685369400217\n",
            "New General Corpus set. Inner PWI at:  0.13556606831947837\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.39415998329075497\n",
            "New General Corpus set. Inner PWI at:  0.2687874731015609\n",
            "New General Corpus set. Inner PWI at:  0.23434745414075533\n",
            "New General Corpus set. Inner PWI at:  0.16439487261155797\n",
            "New General Corpus set. Inner PWI at:  0.15198943228173273\n",
            "New General Corpus set. Inner PWI at:  0.14602152266518353\n",
            "New General Corpus set. Inner PWI at:  0.1273545317904239\n",
            "New General Corpus set. Inner PWI at:  0.1122456069599038\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2614570955406874\n",
            "New General Corpus set. Inner PWI at:  0.18224653833640916\n",
            "New General Corpus set. Inner PWI at:  0.15164592535885885\n",
            "New General Corpus set. Inner PWI at:  0.14171454759466734\n",
            "New General Corpus set. Inner PWI at:  0.12443582732177796\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2538390302911695\n",
            "New General Corpus set. Inner PWI at:  0.2244810410662072\n",
            "New General Corpus set. Inner PWI at:  0.2211480714740746\n",
            "New General Corpus set. Inner PWI at:  0.2006984833319524\n",
            "New General Corpus set. Inner PWI at:  0.17697800953581547\n",
            "New General Corpus set. Inner PWI at:  0.12806765341946072\n",
            "New General Corpus set. Inner PWI at:  0.1183128181390674\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2977888810176258\n",
            "New General Corpus set. Inner PWI at:  0.2474397681146009\n",
            "New General Corpus set. Inner PWI at:  0.20187977078741404\n",
            "New General Corpus set. Inner PWI at:  0.2005023777671398\n",
            "New General Corpus set. Inner PWI at:  0.1495611776309861\n",
            "New General Corpus set. Inner PWI at:  0.12582840953883156\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.23245425465358616\n",
            "New General Corpus set. Inner PWI at:  0.19960779001536932\n",
            "New General Corpus set. Inner PWI at:  0.1576323162326741\n",
            "New General Corpus set. Inner PWI at:  0.13988433313645066\n",
            "Refitting a batch of size  872\n",
            "New General Corpus set. Inner PWI at:  0.1547252160808679\n",
            "New General Corpus set. Inner PWI at:  0.0895729834570399\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2117757803811658\n",
            "New General Corpus set. Inner PWI at:  0.17171532610709567\n",
            "New General Corpus set. Inner PWI at:  0.12014445377946295\n",
            "New General Corpus set. Inner PWI at:  0.11556864114428732\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1797650808454283\n",
            "New General Corpus set. Inner PWI at:  0.14904796206872323\n",
            "New General Corpus set. Inner PWI at:  0.12270420579353462\n",
            "New General Corpus set. Inner PWI at:  0.11544780521809561\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17833907775279878\n",
            "New General Corpus set. Inner PWI at:  0.14784877606845243\n",
            "New General Corpus set. Inner PWI at:  0.13927603582243697\n",
            "New General Corpus set. Inner PWI at:  0.12050612884881778\n",
            "Refitting a batch of size  206\n",
            "New General Corpus set. Inner PWI at:  0.24397777396446524\n",
            "New General Corpus set. Inner PWI at:  0.1955625365123513\n",
            "New General Corpus set. Inner PWI at:  0.1823395080013248\n",
            "New General Corpus set. Inner PWI at:  0.14026959026725236\n",
            "New General Corpus set. Inner PWI at:  0.11901306212873275\n",
            "New General Corpus set. Inner PWI at:  0.07434556423295183\n",
            "Refitting a batch of size  214\n",
            "New General Corpus set. Inner PWI at:  0.29099723567921376\n",
            "New General Corpus set. Inner PWI at:  0.16839235752047732\n",
            "New General Corpus set. Inner PWI at:  0.12389385775021308\n",
            "New General Corpus set. Inner PWI at:  0.10963199962637142\n",
            "Refitting a batch of size  233\n",
            "New General Corpus set. Inner PWI at:  0.1532188879026618\n",
            "New General Corpus set. Inner PWI at:  0.14842556710818933\n",
            "New General Corpus set. Inner PWI at:  0.12492873536888129\n",
            "New General Corpus set. Inner PWI at:  0.12291098959403765\n",
            "New General Corpus set. Inner PWI at:  0.11566755124543897\n",
            "New General Corpus set. Inner PWI at:  0.11198870733126126\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2673661367181327\n",
            "New General Corpus set. Inner PWI at:  0.18972376470064994\n",
            "New General Corpus set. Inner PWI at:  0.18375765200051766\n",
            "New General Corpus set. Inner PWI at:  0.1835254434481275\n",
            "New General Corpus set. Inner PWI at:  0.15302379137954703\n",
            "New General Corpus set. Inner PWI at:  0.1253417331694958\n",
            "Refitting a batch of size  134\n",
            "New General Corpus set. Inner PWI at:  0.16755617693599953\n",
            "New General Corpus set. Inner PWI at:  0.16022389942531862\n",
            "New General Corpus set. Inner PWI at:  0.1564100449154873\n",
            "New General Corpus set. Inner PWI at:  0.11561797279614947\n",
            "Refitting a batch of size  613\n",
            "New General Corpus set. Inner PWI at:  0.17086963042851658\n",
            "New General Corpus set. Inner PWI at:  0.14242580419807682\n",
            "New General Corpus set. Inner PWI at:  0.12849711425430152\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2551868400337428\n",
            "New General Corpus set. Inner PWI at:  0.24244645152048805\n",
            "New General Corpus set. Inner PWI at:  0.19618085020005893\n",
            "New General Corpus set. Inner PWI at:  0.16807968896566333\n",
            "New General Corpus set. Inner PWI at:  0.16557097395179704\n",
            "New General Corpus set. Inner PWI at:  0.1639842947311117\n",
            "New General Corpus set. Inner PWI at:  0.13303464723400724\n",
            "New General Corpus set. Inner PWI at:  0.12942971689964894\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1783707069717423\n",
            "New General Corpus set. Inner PWI at:  0.17611927370068153\n",
            "New General Corpus set. Inner PWI at:  0.14148667932200304\n",
            "New General Corpus set. Inner PWI at:  0.12113460396624393\n",
            "Refitting a batch of size  215\n",
            "New General Corpus set. Inner PWI at:  0.29983041803013344\n",
            "New General Corpus set. Inner PWI at:  0.2621366476855434\n",
            "New General Corpus set. Inner PWI at:  0.22628176245613707\n",
            "New General Corpus set. Inner PWI at:  0.2066937917506138\n",
            "New General Corpus set. Inner PWI at:  0.19603345672027922\n",
            "New General Corpus set. Inner PWI at:  0.16002957941502005\n",
            "New General Corpus set. Inner PWI at:  0.14810499642239516\n",
            "New General Corpus set. Inner PWI at:  0.1171264725189849\n",
            "Refitting a batch of size  275\n",
            "New General Corpus set. Inner PWI at:  0.3415637338705964\n",
            "New General Corpus set. Inner PWI at:  0.19757043493222876\n",
            "New General Corpus set. Inner PWI at:  0.1809488671760341\n",
            "New General Corpus set. Inner PWI at:  0.15286818341413916\n",
            "New General Corpus set. Inner PWI at:  0.14607934935863917\n",
            "New General Corpus set. Inner PWI at:  0.11467139123369767\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.23982964785617208\n",
            "New General Corpus set. Inner PWI at:  0.2097064666837181\n",
            "New General Corpus set. Inner PWI at:  0.19402927208107168\n",
            "New General Corpus set. Inner PWI at:  0.15685418871543863\n",
            "New General Corpus set. Inner PWI at:  0.1538554231471368\n",
            "New General Corpus set. Inner PWI at:  0.14708066275874862\n",
            "New General Corpus set. Inner PWI at:  0.12034215679480537\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.10741209210589801\n",
            "New General Corpus set. Inner PWI at:  0.09751715556652502\n",
            "Refitting a batch of size  1068\n",
            "New General Corpus set. Inner PWI at:  0.32507208585044833\n",
            "New General Corpus set. Inner PWI at:  0.23304612488920978\n",
            "New General Corpus set. Inner PWI at:  0.16918400772450418\n",
            "New General Corpus set. Inner PWI at:  0.14501774878552154\n",
            "New General Corpus set. Inner PWI at:  0.117842854728374\n",
            "New General Corpus set. Inner PWI at:  0.11573546268124939\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3006777252842926\n",
            "New General Corpus set. Inner PWI at:  0.20724253818225105\n",
            "New General Corpus set. Inner PWI at:  0.17826129671174196\n",
            "New General Corpus set. Inner PWI at:  0.15378197959558812\n",
            "New General Corpus set. Inner PWI at:  0.14457767592316872\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3020764101988749\n",
            "New General Corpus set. Inner PWI at:  0.20197567869711947\n",
            "New General Corpus set. Inner PWI at:  0.15902340462251735\n",
            "New General Corpus set. Inner PWI at:  0.11427490650920558\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.26861444426114706\n",
            "New General Corpus set. Inner PWI at:  0.18730527103828915\n",
            "New General Corpus set. Inner PWI at:  0.12709637763209447\n",
            "New General Corpus set. Inner PWI at:  0.12594622057682203\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3272441154763411\n",
            "New General Corpus set. Inner PWI at:  0.23834953818023294\n",
            "New General Corpus set. Inner PWI at:  0.18983407625619267\n",
            "New General Corpus set. Inner PWI at:  0.14720424582220953\n",
            "New General Corpus set. Inner PWI at:  0.08799528596063841\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2034160732433408\n",
            "New General Corpus set. Inner PWI at:  0.1491433230281084\n",
            "New General Corpus set. Inner PWI at:  0.1481499069259004\n",
            "New General Corpus set. Inner PWI at:  0.14312371485816663\n",
            "New General Corpus set. Inner PWI at:  0.12593725841027614\n",
            "New General Corpus set. Inner PWI at:  0.1091779905068086\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.26839024285879504\n",
            "New General Corpus set. Inner PWI at:  0.24776585380257168\n",
            "New General Corpus set. Inner PWI at:  0.24341116534870075\n",
            "New General Corpus set. Inner PWI at:  0.13428007123177718\n",
            "New General Corpus set. Inner PWI at:  0.12142048620830281\n",
            "New General Corpus set. Inner PWI at:  0.11963239147064549\n",
            "Refitting a batch of size  191\n",
            "New General Corpus set. Inner PWI at:  0.29309487516886246\n",
            "New General Corpus set. Inner PWI at:  0.27169902746236085\n",
            "New General Corpus set. Inner PWI at:  0.25448063679696376\n",
            "New General Corpus set. Inner PWI at:  0.16775120054522993\n",
            "New General Corpus set. Inner PWI at:  0.12921901689336907\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16119843610370935\n",
            "New General Corpus set. Inner PWI at:  0.14011410126591403\n",
            "New General Corpus set. Inner PWI at:  0.1300569383080295\n",
            "New General Corpus set. Inner PWI at:  0.10195878026750965\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.15427342235490402\n",
            "New General Corpus set. Inner PWI at:  0.15372030072063203\n",
            "New General Corpus set. Inner PWI at:  0.11425532336952227\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.11703930890918217\n",
            "New General Corpus set. Inner PWI at:  0.11535247623259061\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16490912351327167\n",
            "New General Corpus set. Inner PWI at:  0.14744409287055574\n",
            "New General Corpus set. Inner PWI at:  0.14668699532204346\n",
            "New General Corpus set. Inner PWI at:  0.12688221168344452\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.28330040981820176\n",
            "New General Corpus set. Inner PWI at:  0.2735942850814768\n",
            "New General Corpus set. Inner PWI at:  0.26960977705606504\n",
            "New General Corpus set. Inner PWI at:  0.22900450361083605\n",
            "New General Corpus set. Inner PWI at:  0.22036950092801266\n",
            "New General Corpus set. Inner PWI at:  0.17978307890972992\n",
            "New General Corpus set. Inner PWI at:  0.12347827696961866\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.15555064368072033\n",
            "New General Corpus set. Inner PWI at:  0.13370729908214485\n",
            "New General Corpus set. Inner PWI at:  0.12058675605811059\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3249360330957704\n",
            "New General Corpus set. Inner PWI at:  0.2992443730845237\n",
            "New General Corpus set. Inner PWI at:  0.22151863520357243\n",
            "New General Corpus set. Inner PWI at:  0.2115526731185463\n",
            "New General Corpus set. Inner PWI at:  0.17128780011578842\n",
            "New General Corpus set. Inner PWI at:  0.17077030299518692\n",
            "New General Corpus set. Inner PWI at:  0.1556558689013733\n",
            "New General Corpus set. Inner PWI at:  0.1063702019613703\n",
            "Refitting a batch of size  128\n",
            "New General Corpus set. Inner PWI at:  0.2635643632968646\n",
            "New General Corpus set. Inner PWI at:  0.16523918875220003\n",
            "New General Corpus set. Inner PWI at:  0.1519251764469075\n",
            "New General Corpus set. Inner PWI at:  0.1480441231101158\n",
            "New General Corpus set. Inner PWI at:  0.1478228162151453\n",
            "New General Corpus set. Inner PWI at:  0.12731944608656878\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.12129636477413062\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.21805422720828976\n",
            "New General Corpus set. Inner PWI at:  0.2112623431964173\n",
            "New General Corpus set. Inner PWI at:  0.18398498530182983\n",
            "New General Corpus set. Inner PWI at:  0.15181547085931885\n",
            "New General Corpus set. Inner PWI at:  0.1357471004353353\n",
            "New General Corpus set. Inner PWI at:  0.1323885279822138\n",
            "New General Corpus set. Inner PWI at:  0.12192823722726112\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.14400392248398095\n",
            "New General Corpus set. Inner PWI at:  0.12569832675606563\n",
            "New General Corpus set. Inner PWI at:  0.08798838653367268\n",
            "New General Corpus set. Inner PWI at:  0.06116955190995684\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3726440397693779\n",
            "New General Corpus set. Inner PWI at:  0.2591872003444352\n",
            "New General Corpus set. Inner PWI at:  0.2524826498389497\n",
            "New General Corpus set. Inner PWI at:  0.24504646412638972\n",
            "New General Corpus set. Inner PWI at:  0.20160977480132555\n",
            "New General Corpus set. Inner PWI at:  0.1652954642102378\n",
            "New General Corpus set. Inner PWI at:  0.16230185646858838\n",
            "New General Corpus set. Inner PWI at:  0.1609257023857045\n",
            "New General Corpus set. Inner PWI at:  0.15765330365403218\n",
            "New General Corpus set. Inner PWI at:  0.14003356390991514\n",
            "New General Corpus set. Inner PWI at:  0.1326482083506313\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.22111152328260386\n",
            "New General Corpus set. Inner PWI at:  0.20883406980630181\n",
            "New General Corpus set. Inner PWI at:  0.19173951181421944\n",
            "New General Corpus set. Inner PWI at:  0.1292879459760205\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.12423225274892681\n",
            "Refitting a batch of size  138\n",
            "New General Corpus set. Inner PWI at:  0.2129312428063802\n",
            "New General Corpus set. Inner PWI at:  0.11153417657689309\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1519001671730238\n",
            "New General Corpus set. Inner PWI at:  0.129902162801694\n",
            "New General Corpus set. Inner PWI at:  0.11956655105058994\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.33248819967666854\n",
            "New General Corpus set. Inner PWI at:  0.14409268094691233\n",
            "New General Corpus set. Inner PWI at:  0.13157383942584502\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2389148172391949\n",
            "New General Corpus set. Inner PWI at:  0.22928586157000036\n",
            "New General Corpus set. Inner PWI at:  0.17452748760570272\n",
            "New General Corpus set. Inner PWI at:  0.15960216032383462\n",
            "New General Corpus set. Inner PWI at:  0.15774232425461615\n",
            "New General Corpus set. Inner PWI at:  0.1551505181394651\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20494203347532497\n",
            "New General Corpus set. Inner PWI at:  0.18374914014194416\n",
            "New General Corpus set. Inner PWI at:  0.18041287183021712\n",
            "New General Corpus set. Inner PWI at:  0.17076894117990185\n",
            "New General Corpus set. Inner PWI at:  0.15039473569853798\n",
            "New General Corpus set. Inner PWI at:  0.14190841813350596\n",
            "New General Corpus set. Inner PWI at:  0.09983540219931078\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.23384005616024695\n",
            "New General Corpus set. Inner PWI at:  0.1910544932167036\n",
            "New General Corpus set. Inner PWI at:  0.16463902012643672\n",
            "New General Corpus set. Inner PWI at:  0.13167868039166217\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.21208597896551248\n",
            "New General Corpus set. Inner PWI at:  0.20122518518688878\n",
            "New General Corpus set. Inner PWI at:  0.1701885406819546\n",
            "New General Corpus set. Inner PWI at:  0.16226295983975986\n",
            "New General Corpus set. Inner PWI at:  0.16037927214120837\n",
            "New General Corpus set. Inner PWI at:  0.15538879245239806\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2109640996169502\n",
            "New General Corpus set. Inner PWI at:  0.13386439362823627\n",
            "New General Corpus set. Inner PWI at:  0.1261116485335291\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20424196719061832\n",
            "New General Corpus set. Inner PWI at:  0.18152779179381864\n",
            "New General Corpus set. Inner PWI at:  0.13555790468537346\n",
            "New General Corpus set. Inner PWI at:  0.12536895200482132\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20589393298217423\n",
            "New General Corpus set. Inner PWI at:  0.16035779219327378\n",
            "New General Corpus set. Inner PWI at:  0.1245643100895675\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2247677492851752\n",
            "New General Corpus set. Inner PWI at:  0.17682453055516906\n",
            "New General Corpus set. Inner PWI at:  0.16247432544581356\n",
            "New General Corpus set. Inner PWI at:  0.15952553196382255\n",
            "New General Corpus set. Inner PWI at:  0.15477504573407752\n",
            "New General Corpus set. Inner PWI at:  0.15039709067673773\n",
            "New General Corpus set. Inner PWI at:  0.1257566321334416\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.19226236072339128\n",
            "New General Corpus set. Inner PWI at:  0.10069013186121444\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17040233147752634\n",
            "New General Corpus set. Inner PWI at:  0.14167287840593043\n",
            "New General Corpus set. Inner PWI at:  0.10453552045649239\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2374741083942979\n",
            "New General Corpus set. Inner PWI at:  0.21156405847660775\n",
            "New General Corpus set. Inner PWI at:  0.10747506280170104\n",
            "New General Corpus set. Inner PWI at:  0.10184512158160446\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.24457509538534866\n",
            "New General Corpus set. Inner PWI at:  0.17443529587515497\n",
            "New General Corpus set. Inner PWI at:  0.16173815536260464\n",
            "New General Corpus set. Inner PWI at:  0.13771662359422257\n",
            "New General Corpus set. Inner PWI at:  0.13452984886535735\n",
            "New General Corpus set. Inner PWI at:  0.13319201051252888\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2607805123282815\n",
            "New General Corpus set. Inner PWI at:  0.22738938539522258\n",
            "New General Corpus set. Inner PWI at:  0.18617126846404797\n",
            "New General Corpus set. Inner PWI at:  0.12156496263009131\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20808683340331482\n",
            "New General Corpus set. Inner PWI at:  0.16839679782838204\n",
            "New General Corpus set. Inner PWI at:  0.15731055759656096\n",
            "New General Corpus set. Inner PWI at:  0.14728320512712764\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20084174183802284\n",
            "New General Corpus set. Inner PWI at:  0.17239380196244591\n",
            "New General Corpus set. Inner PWI at:  0.13079647423613852\n",
            "New General Corpus set. Inner PWI at:  0.12624261395788464\n",
            "New General Corpus set. Inner PWI at:  0.12487286384999594\n",
            "Refitting a batch of size  318\n",
            "New General Corpus set. Inner PWI at:  0.2303597107289522\n",
            "New General Corpus set. Inner PWI at:  0.20454471877446523\n",
            "New General Corpus set. Inner PWI at:  0.17452221771456178\n",
            "New General Corpus set. Inner PWI at:  0.15856215210322605\n",
            "New General Corpus set. Inner PWI at:  0.15284555548813467\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3038927782761272\n",
            "New General Corpus set. Inner PWI at:  0.2339000424204573\n",
            "New General Corpus set. Inner PWI at:  0.198015328419128\n",
            "New General Corpus set. Inner PWI at:  0.12531755456565022\n",
            "New General Corpus set. Inner PWI at:  0.11633574786176772\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3462115152692304\n",
            "New General Corpus set. Inner PWI at:  0.3142643203582383\n",
            "New General Corpus set. Inner PWI at:  0.2309927618703887\n",
            "New General Corpus set. Inner PWI at:  0.1816193930492985\n",
            "New General Corpus set. Inner PWI at:  0.16623220675937955\n",
            "New General Corpus set. Inner PWI at:  0.15478244267516791\n",
            "New General Corpus set. Inner PWI at:  0.13337472135304068\n",
            "New General Corpus set. Inner PWI at:  0.1322765145634918\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.22479794409890316\n",
            "New General Corpus set. Inner PWI at:  0.19060139194302086\n",
            "New General Corpus set. Inner PWI at:  0.1592347677582308\n",
            "New General Corpus set. Inner PWI at:  0.14574728081038102\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17360128475266487\n",
            "New General Corpus set. Inner PWI at:  0.13821397705074262\n",
            "New General Corpus set. Inner PWI at:  0.13043677614399612\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2247059372022711\n",
            "New General Corpus set. Inner PWI at:  0.20508337894818984\n",
            "New General Corpus set. Inner PWI at:  0.17823255714211897\n",
            "New General Corpus set. Inner PWI at:  0.17689863108305837\n",
            "New General Corpus set. Inner PWI at:  0.157915045502766\n",
            "New General Corpus set. Inner PWI at:  0.13646538038845477\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.19883366084904291\n",
            "New General Corpus set. Inner PWI at:  0.16587788479969598\n",
            "New General Corpus set. Inner PWI at:  0.16358686882707604\n",
            "New General Corpus set. Inner PWI at:  0.12813482273769458\n",
            "New General Corpus set. Inner PWI at:  0.12569369080681866\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.32988911089353423\n",
            "New General Corpus set. Inner PWI at:  0.14767507191762214\n",
            "New General Corpus set. Inner PWI at:  0.13755066159121576\n",
            "New General Corpus set. Inner PWI at:  0.11488272222485635\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2646327620759721\n",
            "New General Corpus set. Inner PWI at:  0.23701527824473312\n",
            "New General Corpus set. Inner PWI at:  0.213047746251438\n",
            "New General Corpus set. Inner PWI at:  0.18243799188358348\n",
            "New General Corpus set. Inner PWI at:  0.17936293952159285\n",
            "New General Corpus set. Inner PWI at:  0.1513084106191263\n",
            "New General Corpus set. Inner PWI at:  0.1373314799392553\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.226532606126583\n",
            "New General Corpus set. Inner PWI at:  0.17385872324977542\n",
            "New General Corpus set. Inner PWI at:  0.16867425434587976\n",
            "New General Corpus set. Inner PWI at:  0.12055783187757449\n",
            "New General Corpus set. Inner PWI at:  0.10667692043924824\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16047164798842556\n",
            "New General Corpus set. Inner PWI at:  0.14096054300158653\n",
            "New General Corpus set. Inner PWI at:  0.12510091028039058\n",
            "New General Corpus set. Inner PWI at:  0.11485481771761936\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.22056276159043126\n",
            "New General Corpus set. Inner PWI at:  0.12978451111613168\n",
            "New General Corpus set. Inner PWI at:  0.10623377280586174\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16939814844059736\n",
            "New General Corpus set. Inner PWI at:  0.1419127964461687\n",
            "New General Corpus set. Inner PWI at:  0.14190164770649177\n",
            "New General Corpus set. Inner PWI at:  0.13395383228526803\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2721224393573528\n",
            "New General Corpus set. Inner PWI at:  0.19214708301197983\n",
            "New General Corpus set. Inner PWI at:  0.1377769828044073\n",
            "New General Corpus set. Inner PWI at:  0.12275080835341833\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20743584036736482\n",
            "New General Corpus set. Inner PWI at:  0.1713982320703771\n",
            "New General Corpus set. Inner PWI at:  0.15047384770963232\n",
            "Refitting a batch of size  289\n",
            "New General Corpus set. Inner PWI at:  0.2961652432662718\n",
            "New General Corpus set. Inner PWI at:  0.23521492924668094\n",
            "New General Corpus set. Inner PWI at:  0.21915347432204588\n",
            "New General Corpus set. Inner PWI at:  0.19736864130945675\n",
            "New General Corpus set. Inner PWI at:  0.13692633225866307\n",
            "New General Corpus set. Inner PWI at:  0.13604572331996787\n",
            "New General Corpus set. Inner PWI at:  0.13318368165953953\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.19544992996948218\n",
            "New General Corpus set. Inner PWI at:  0.14988205295621965\n",
            "New General Corpus set. Inner PWI at:  0.13753788033167016\n",
            "New General Corpus set. Inner PWI at:  0.09418142338296961\n",
            "Refitting a batch of size  171\n",
            "New General Corpus set. Inner PWI at:  0.2770810885248924\n",
            "New General Corpus set. Inner PWI at:  0.15583085989311402\n",
            "New General Corpus set. Inner PWI at:  0.14130437846589677\n",
            "New General Corpus set. Inner PWI at:  0.12184094381783588\n",
            "New General Corpus set. Inner PWI at:  0.09717009612264295\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2146570689599845\n",
            "New General Corpus set. Inner PWI at:  0.1678523497251796\n",
            "New General Corpus set. Inner PWI at:  0.1261483570963497\n",
            "New General Corpus set. Inner PWI at:  0.11669958500631418\n",
            "New General Corpus set. Inner PWI at:  0.10685094377105958\n",
            "New General Corpus set. Inner PWI at:  0.10537662368623435\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2278602379107444\n",
            "New General Corpus set. Inner PWI at:  0.19770063229184986\n",
            "New General Corpus set. Inner PWI at:  0.11603378172114186\n",
            "New General Corpus set. Inner PWI at:  0.10455956304500719\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.20175493971875116\n",
            "New General Corpus set. Inner PWI at:  0.18793780051306563\n",
            "New General Corpus set. Inner PWI at:  0.17171459268203412\n",
            "New General Corpus set. Inner PWI at:  0.1560917235068411\n",
            "New General Corpus set. Inner PWI at:  0.1524973992050053\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.30088084508145413\n",
            "New General Corpus set. Inner PWI at:  0.15497153887892695\n",
            "New General Corpus set. Inner PWI at:  0.1223985193666365\n",
            "New General Corpus set. Inner PWI at:  0.09317147341524123\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.27061589656924223\n",
            "New General Corpus set. Inner PWI at:  0.2593950729235553\n",
            "New General Corpus set. Inner PWI at:  0.1669257771373858\n",
            "New General Corpus set. Inner PWI at:  0.15308364832559235\n",
            "New General Corpus set. Inner PWI at:  0.1426681686111617\n",
            "New General Corpus set. Inner PWI at:  0.10351470962918832\n",
            "New General Corpus set. Inner PWI at:  0.09984694561899282\n",
            "New General Corpus set. Inner PWI at:  0.09376766871979501\n",
            "Refitting a batch of size  127\n",
            "New General Corpus set. Inner PWI at:  0.17523366558691394\n",
            "New General Corpus set. Inner PWI at:  0.16412373876007436\n",
            "New General Corpus set. Inner PWI at:  0.1413215956827318\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2968898516082961\n",
            "New General Corpus set. Inner PWI at:  0.26160293798490675\n",
            "New General Corpus set. Inner PWI at:  0.22419150920903813\n",
            "New General Corpus set. Inner PWI at:  0.21131333249354495\n",
            "New General Corpus set. Inner PWI at:  0.1555706063826834\n",
            "New General Corpus set. Inner PWI at:  0.1450906490893312\n",
            "New General Corpus set. Inner PWI at:  0.128598264388645\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.24502140620680135\n",
            "New General Corpus set. Inner PWI at:  0.16945462608330908\n",
            "New General Corpus set. Inner PWI at:  0.16027997079504683\n",
            "New General Corpus set. Inner PWI at:  0.1578605702714537\n",
            "New General Corpus set. Inner PWI at:  0.15050188014607369\n",
            "New General Corpus set. Inner PWI at:  0.127609567071315\n",
            "New General Corpus set. Inner PWI at:  0.07332154844183657\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.31976170157735606\n",
            "New General Corpus set. Inner PWI at:  0.2994794726035089\n",
            "New General Corpus set. Inner PWI at:  0.28686382609781574\n",
            "New General Corpus set. Inner PWI at:  0.251826364882455\n",
            "New General Corpus set. Inner PWI at:  0.24279740367777816\n",
            "New General Corpus set. Inner PWI at:  0.24056540025143416\n",
            "New General Corpus set. Inner PWI at:  0.22921840526880818\n",
            "New General Corpus set. Inner PWI at:  0.1296428528999967\n",
            "New General Corpus set. Inner PWI at:  0.12862973158596056\n",
            "New General Corpus set. Inner PWI at:  0.10617313876979778\n",
            "Refitting a batch of size  112\n",
            "New General Corpus set. Inner PWI at:  0.1313518906496618\n",
            "New General Corpus set. Inner PWI at:  0.12310863143095739\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.13284824391479588\n",
            "New General Corpus set. Inner PWI at:  0.12149914837798961\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.26614593497895667\n",
            "New General Corpus set. Inner PWI at:  0.10793807480917617\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.24013676061541944\n",
            "New General Corpus set. Inner PWI at:  0.14643065487314058\n",
            "New General Corpus set. Inner PWI at:  0.1390129031647889\n",
            "New General Corpus set. Inner PWI at:  0.13701197563818632\n",
            "New General Corpus set. Inner PWI at:  0.13011475472986928\n",
            "New General Corpus set. Inner PWI at:  0.11290948109276512\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2718322002474464\n",
            "New General Corpus set. Inner PWI at:  0.21858448859505353\n",
            "New General Corpus set. Inner PWI at:  0.08746921091681392\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.30239137630605045\n",
            "New General Corpus set. Inner PWI at:  0.22929333730840742\n",
            "New General Corpus set. Inner PWI at:  0.22860751394987458\n",
            "New General Corpus set. Inner PWI at:  0.21656013109554786\n",
            "New General Corpus set. Inner PWI at:  0.16569858957055458\n",
            "New General Corpus set. Inner PWI at:  0.15098070384639886\n",
            "New General Corpus set. Inner PWI at:  0.14585015488608957\n",
            "New General Corpus set. Inner PWI at:  0.14400584489734997\n",
            "New General Corpus set. Inner PWI at:  0.12429452307692998\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2568874356534277\n",
            "New General Corpus set. Inner PWI at:  0.24000009393488586\n",
            "New General Corpus set. Inner PWI at:  0.11709903444596018\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17450163512576608\n",
            "New General Corpus set. Inner PWI at:  0.145070080928839\n",
            "New General Corpus set. Inner PWI at:  0.14218267024196743\n",
            "New General Corpus set. Inner PWI at:  0.11396502600485149\n",
            "New General Corpus set. Inner PWI at:  0.10909942804986586\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2530524229332632\n",
            "New General Corpus set. Inner PWI at:  0.21508895624904956\n",
            "New General Corpus set. Inner PWI at:  0.16850403982190776\n",
            "New General Corpus set. Inner PWI at:  0.15519446464410525\n",
            "New General Corpus set. Inner PWI at:  0.1493038283437283\n",
            "New General Corpus set. Inner PWI at:  0.1400816095649647\n",
            "New General Corpus set. Inner PWI at:  0.13973860462009746\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.31680459415446516\n",
            "New General Corpus set. Inner PWI at:  0.1730737835225199\n",
            "New General Corpus set. Inner PWI at:  0.15455462177157023\n",
            "New General Corpus set. Inner PWI at:  0.12764309254766218\n",
            "New General Corpus set. Inner PWI at:  0.11582426057226333\n",
            "New General Corpus set. Inner PWI at:  0.10531495337625227\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17321110577786367\n",
            "New General Corpus set. Inner PWI at:  0.15844794875446877\n",
            "New General Corpus set. Inner PWI at:  0.1380356290557346\n",
            "New General Corpus set. Inner PWI at:  0.13615734375038277\n",
            "New General Corpus set. Inner PWI at:  0.08154750632612634\n",
            "Refitting a batch of size  137\n",
            "New General Corpus set. Inner PWI at:  0.3023187026127047\n",
            "New General Corpus set. Inner PWI at:  0.24622862859229358\n",
            "New General Corpus set. Inner PWI at:  0.1476950355019131\n",
            "New General Corpus set. Inner PWI at:  0.12386895346806724\n",
            "New General Corpus set. Inner PWI at:  0.11734997269935597\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1353366626760015\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.26670403159711564\n",
            "New General Corpus set. Inner PWI at:  0.19516527211991316\n",
            "New General Corpus set. Inner PWI at:  0.15213335309686493\n",
            "New General Corpus set. Inner PWI at:  0.1445120985553009\n",
            "New General Corpus set. Inner PWI at:  0.12297048595374885\n",
            "New General Corpus set. Inner PWI at:  0.10858899928940315\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.14503337899419308\n",
            "New General Corpus set. Inner PWI at:  0.12860692877405427\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.25430452708357076\n",
            "New General Corpus set. Inner PWI at:  0.123008793233811\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.23029909660206774\n",
            "New General Corpus set. Inner PWI at:  0.1869520723681901\n",
            "New General Corpus set. Inner PWI at:  0.11671614816799131\n",
            "New General Corpus set. Inner PWI at:  0.108692714503209\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2059368728647254\n",
            "New General Corpus set. Inner PWI at:  0.19661804341453765\n",
            "New General Corpus set. Inner PWI at:  0.14312232336557554\n",
            "New General Corpus set. Inner PWI at:  0.1430790985640755\n",
            "New General Corpus set. Inner PWI at:  0.14136296395545928\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2257419208808463\n",
            "New General Corpus set. Inner PWI at:  0.1772675115466311\n",
            "New General Corpus set. Inner PWI at:  0.16200095742852116\n",
            "New General Corpus set. Inner PWI at:  0.15298951564277213\n",
            "New General Corpus set. Inner PWI at:  0.1345283290299899\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.3017231340783071\n",
            "New General Corpus set. Inner PWI at:  0.1481556639956849\n",
            "New General Corpus set. Inner PWI at:  0.14149042546500787\n",
            "New General Corpus set. Inner PWI at:  0.12983296132208394\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.26119135669882654\n",
            "New General Corpus set. Inner PWI at:  0.194760518415365\n",
            "New General Corpus set. Inner PWI at:  0.1932631041502333\n",
            "New General Corpus set. Inner PWI at:  0.17794639659418643\n",
            "New General Corpus set. Inner PWI at:  0.17640819670785887\n",
            "New General Corpus set. Inner PWI at:  0.16457138196098484\n",
            "New General Corpus set. Inner PWI at:  0.1632938766995946\n",
            "New General Corpus set. Inner PWI at:  0.16270538171490867\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.17843650288336702\n",
            "New General Corpus set. Inner PWI at:  0.16808236807727955\n",
            "New General Corpus set. Inner PWI at:  0.10230809257523203\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.19683822393508224\n",
            "New General Corpus set. Inner PWI at:  0.16244402019429555\n",
            "New General Corpus set. Inner PWI at:  0.15996409994975058\n",
            "New General Corpus set. Inner PWI at:  0.13955087240888783\n",
            "New General Corpus set. Inner PWI at:  0.10317822398068711\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16365191648911262\n",
            "New General Corpus set. Inner PWI at:  0.15887093821349857\n",
            "New General Corpus set. Inner PWI at:  0.11573032779902892\n",
            "New General Corpus set. Inner PWI at:  0.10130640253319953\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2305141834201781\n",
            "New General Corpus set. Inner PWI at:  0.22762606875642177\n",
            "New General Corpus set. Inner PWI at:  0.19790196446739206\n",
            "New General Corpus set. Inner PWI at:  0.18343891842387688\n",
            "New General Corpus set. Inner PWI at:  0.14782158728659456\n",
            "New General Corpus set. Inner PWI at:  0.12935342320880847\n",
            "New General Corpus set. Inner PWI at:  0.11036148581057101\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.18958196364753138\n",
            "New General Corpus set. Inner PWI at:  0.12962394588388593\n",
            "New General Corpus set. Inner PWI at:  0.116887180291669\n",
            "New General Corpus set. Inner PWI at:  0.09817160640021111\n",
            "Refitting a batch of size  119\n",
            "New General Corpus set. Inner PWI at:  0.3445049481546854\n",
            "New General Corpus set. Inner PWI at:  0.1557866157760356\n",
            "New General Corpus set. Inner PWI at:  0.14618473923537656\n",
            "New General Corpus set. Inner PWI at:  0.1420990785390166\n",
            "New General Corpus set. Inner PWI at:  0.11139183507243697\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.1192266873495555\n",
            "New General Corpus set. Inner PWI at:  0.11169947179225206\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.2217730577266046\n",
            "New General Corpus set. Inner PWI at:  0.18521995559405954\n",
            "New General Corpus set. Inner PWI at:  0.18265935940190373\n",
            "New General Corpus set. Inner PWI at:  0.16590072260308492\n",
            "New General Corpus set. Inner PWI at:  0.16346599116832208\n",
            "New General Corpus set. Inner PWI at:  0.1622364000092546\n",
            "New General Corpus set. Inner PWI at:  0.13301956374754526\n",
            "New General Corpus set. Inner PWI at:  0.11114965998860182\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.16813161534377746\n",
            "New General Corpus set. Inner PWI at:  0.1614109947800354\n",
            "New General Corpus set. Inner PWI at:  0.14821197419957852\n",
            "New General Corpus set. Inner PWI at:  0.12221505664843822\n",
            "New General Corpus set. Inner PWI at:  0.07525544860958555\n",
            "Refitting a batch of size  100\n",
            "New General Corpus set. Inner PWI at:  0.28857873368182013\n",
            "New General Corpus set. Inner PWI at:  0.22705071744444377\n",
            "New General Corpus set. Inner PWI at:  0.19820820843171946\n",
            "New General Corpus set. Inner PWI at:  0.18430936093211753\n",
            "New General Corpus set. Inner PWI at:  0.1642908851374873\n",
            "New General Corpus set. Inner PWI at:  0.16072684624443212\n",
            "New General Corpus set. Inner PWI at:  0.13165009460621296\n",
            "New General Corpus set. Inner PWI at:  0.11875101580348023\n",
            "Refitting a batch of size  129\n",
            "New General Corpus set. Inner PWI at:  0.1955372347452482\n",
            "New General Corpus set. Inner PWI at:  0.17293327547619067\n",
            "New General Corpus set. Inner PWI at:  0.1418944785466927\n",
            "New General Corpus set. Inner PWI at:  0.13893031670974865\n",
            "New General Corpus set. Inner PWI at:  0.12279264950600359\n",
            "Refitting a batch of size  215\n",
            "New General Corpus set. Inner PWI at:  0.16395721615154363\n",
            "New General Corpus set. Inner PWI at:  0.14775941391256514\n",
            "New General Corpus set. Inner PWI at:  0.12369391331021506\n",
            "New General Corpus set. Inner PWI at:  0.10390334914480419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ROC-AUC  Precision    Recall  F1-Score  Accuracy\n",
              "2019-06-01  0.483454   0.452413  0.483454  0.382804  0.483454\n",
              "2019-07-01  0.478158   0.456958  0.478158  0.404879  0.478158\n",
              "2019-08-01  0.495652   0.474215  0.495652  0.363321  0.495652\n",
              "2019-09-01  0.514483   0.514488  0.514483  0.514437  0.514483\n",
              "2019-10-01  0.449324   0.446605  0.449324  0.442222  0.449324\n",
              "2019-11-01  0.530025   0.549646  0.530025  0.478495  0.530025\n",
              "2019-12-01  0.508224   0.528824  0.508224  0.401242  0.508224\n",
              "2020-01-01  0.495822   0.482580  0.495822  0.377529  0.495822\n",
              "2020-02-01  0.481050   0.455911  0.481050  0.394778  0.481050\n",
              "2020-03-01  0.515957   0.535642  0.515957  0.438419  0.515957\n",
              "2020-04-01  0.491969   0.476565  0.491969  0.425363  0.575727\n",
              "2020-05-01  0.463158   0.455772  0.463158  0.452762  0.516327\n",
              "2020-06-01  0.500000   0.368550  0.500000  0.424328  0.737101"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bdf7377-e22f-48f8-880b-09a1aa293d67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROC-AUC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-06-01</th>\n",
              "      <td>0.483454</td>\n",
              "      <td>0.452413</td>\n",
              "      <td>0.483454</td>\n",
              "      <td>0.382804</td>\n",
              "      <td>0.483454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01</th>\n",
              "      <td>0.478158</td>\n",
              "      <td>0.456958</td>\n",
              "      <td>0.478158</td>\n",
              "      <td>0.404879</td>\n",
              "      <td>0.478158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>0.495652</td>\n",
              "      <td>0.474215</td>\n",
              "      <td>0.495652</td>\n",
              "      <td>0.363321</td>\n",
              "      <td>0.495652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-01</th>\n",
              "      <td>0.514483</td>\n",
              "      <td>0.514488</td>\n",
              "      <td>0.514483</td>\n",
              "      <td>0.514437</td>\n",
              "      <td>0.514483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-01</th>\n",
              "      <td>0.449324</td>\n",
              "      <td>0.446605</td>\n",
              "      <td>0.449324</td>\n",
              "      <td>0.442222</td>\n",
              "      <td>0.449324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-01</th>\n",
              "      <td>0.530025</td>\n",
              "      <td>0.549646</td>\n",
              "      <td>0.530025</td>\n",
              "      <td>0.478495</td>\n",
              "      <td>0.530025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-01</th>\n",
              "      <td>0.508224</td>\n",
              "      <td>0.528824</td>\n",
              "      <td>0.508224</td>\n",
              "      <td>0.401242</td>\n",
              "      <td>0.508224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-01</th>\n",
              "      <td>0.495822</td>\n",
              "      <td>0.482580</td>\n",
              "      <td>0.495822</td>\n",
              "      <td>0.377529</td>\n",
              "      <td>0.495822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01</th>\n",
              "      <td>0.481050</td>\n",
              "      <td>0.455911</td>\n",
              "      <td>0.481050</td>\n",
              "      <td>0.394778</td>\n",
              "      <td>0.481050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01</th>\n",
              "      <td>0.515957</td>\n",
              "      <td>0.535642</td>\n",
              "      <td>0.515957</td>\n",
              "      <td>0.438419</td>\n",
              "      <td>0.515957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-01</th>\n",
              "      <td>0.491969</td>\n",
              "      <td>0.476565</td>\n",
              "      <td>0.491969</td>\n",
              "      <td>0.425363</td>\n",
              "      <td>0.575727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-01</th>\n",
              "      <td>0.463158</td>\n",
              "      <td>0.455772</td>\n",
              "      <td>0.463158</td>\n",
              "      <td>0.452762</td>\n",
              "      <td>0.516327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-01</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.368550</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.424328</td>\n",
              "      <td>0.737101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bdf7377-e22f-48f8-880b-09a1aa293d67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bdf7377-e22f-48f8-880b-09a1aa293d67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bdf7377-e22f-48f8-880b-09a1aa293d67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 500"
      ],
      "metadata": {
        "id": "Eb-Q2k2ayCJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact = Artifact(training_data, model, 500)\n",
        "test_data = timeSampledDF[test].reset_index(drop=True)\n",
        "fullPred = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  fullPred.append(artifact.predict(test_data.loc[i, 'Text']))\n",
        "  artifact.add_data(test_data.loc[i, 'Text'], test_data.loc[i, 'Abgelehnt'])\n",
        "\n",
        "results = timeSampledDF[test]\n",
        "results['y_pred'] = fullPred\n",
        "testMonthly(results, results.Abgelehnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ODyoYlShyEa0",
        "outputId": "928821e6-f221-4e81-a483-1e5b80d66cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2625330167909137\n",
            "New General Corpus set. Inner PWI at:  0.23384615828770883\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2941441802199233\n",
            "New General Corpus set. Inner PWI at:  0.259925050577095\n",
            "New General Corpus set. Inner PWI at:  0.23203034329824304\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2894565972310512\n",
            "New General Corpus set. Inner PWI at:  0.28401492661873623\n",
            "New General Corpus set. Inner PWI at:  0.27756356937885074\n",
            "New General Corpus set. Inner PWI at:  0.24248301579374207\n",
            "New General Corpus set. Inner PWI at:  0.23142162637261451\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3311829422049995\n",
            "New General Corpus set. Inner PWI at:  0.2635698865940111\n",
            "New General Corpus set. Inner PWI at:  0.2632800448911131\n",
            "New General Corpus set. Inner PWI at:  0.2611828730212823\n",
            "New General Corpus set. Inner PWI at:  0.24530432511741745\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3130474299436935\n",
            "New General Corpus set. Inner PWI at:  0.29774886950474355\n",
            "New General Corpus set. Inner PWI at:  0.2531794035705712\n",
            "New General Corpus set. Inner PWI at:  0.22684796590468007\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.30971292018237007\n",
            "New General Corpus set. Inner PWI at:  0.3087879595507467\n",
            "New General Corpus set. Inner PWI at:  0.24495528184939147\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.31159680123506645\n",
            "New General Corpus set. Inner PWI at:  0.30279274558348035\n",
            "New General Corpus set. Inner PWI at:  0.27120114716664584\n",
            "New General Corpus set. Inner PWI at:  0.2626458459288681\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3156953475680739\n",
            "New General Corpus set. Inner PWI at:  0.2745840978751339\n",
            "New General Corpus set. Inner PWI at:  0.25541921425731917\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3641789324807093\n",
            "New General Corpus set. Inner PWI at:  0.29154909748210805\n",
            "New General Corpus set. Inner PWI at:  0.27293135183335887\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3050619376268704\n",
            "New General Corpus set. Inner PWI at:  0.25787372269747927\n",
            "New General Corpus set. Inner PWI at:  0.25175384395059447\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3300650306266979\n",
            "New General Corpus set. Inner PWI at:  0.2950136087053272\n",
            "New General Corpus set. Inner PWI at:  0.2902392552098838\n",
            "New General Corpus set. Inner PWI at:  0.2895228901912846\n",
            "New General Corpus set. Inner PWI at:  0.2597231775556179\n",
            "New General Corpus set. Inner PWI at:  0.2558096991347339\n",
            "New General Corpus set. Inner PWI at:  0.2520996769480932\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3006419459849914\n",
            "New General Corpus set. Inner PWI at:  0.2857736047213545\n",
            "New General Corpus set. Inner PWI at:  0.2804982351468506\n",
            "New General Corpus set. Inner PWI at:  0.2628611376002996\n",
            "New General Corpus set. Inner PWI at:  0.24819558967696354\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2902786740943991\n",
            "New General Corpus set. Inner PWI at:  0.2894765007784527\n",
            "New General Corpus set. Inner PWI at:  0.27916063702501653\n",
            "New General Corpus set. Inner PWI at:  0.260136390543842\n",
            "New General Corpus set. Inner PWI at:  0.2457607503769709\n",
            "New General Corpus set. Inner PWI at:  0.23413594858340794\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.25711828446142354\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.25534053789911987\n",
            "New General Corpus set. Inner PWI at:  0.25480297704044147\n",
            "New General Corpus set. Inner PWI at:  0.2428609758368578\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3085303926763385\n",
            "New General Corpus set. Inner PWI at:  0.2192912571369111\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2830559990108031\n",
            "New General Corpus set. Inner PWI at:  0.27370100922527785\n",
            "New General Corpus set. Inner PWI at:  0.2720581783825235\n",
            "New General Corpus set. Inner PWI at:  0.27144323160335815\n",
            "New General Corpus set. Inner PWI at:  0.2501428268949995\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.29388214622096176\n",
            "New General Corpus set. Inner PWI at:  0.2673722092954592\n",
            "New General Corpus set. Inner PWI at:  0.21999024012520368\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3005900022027241\n",
            "New General Corpus set. Inner PWI at:  0.28165543018068995\n",
            "New General Corpus set. Inner PWI at:  0.25323898962354807\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.25754072071032297\n",
            "New General Corpus set. Inner PWI at:  0.23368607886878706\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.22446679693960075\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.32666489302582025\n",
            "New General Corpus set. Inner PWI at:  0.27871414070086076\n",
            "New General Corpus set. Inner PWI at:  0.2394924566829741\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.39505760760072617\n",
            "New General Corpus set. Inner PWI at:  0.2743105985226657\n",
            "New General Corpus set. Inner PWI at:  0.27099592346398854\n",
            "New General Corpus set. Inner PWI at:  0.24828510737684042\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3341743655496128\n",
            "New General Corpus set. Inner PWI at:  0.2635291756372081\n",
            "New General Corpus set. Inner PWI at:  0.257638286899609\n",
            "New General Corpus set. Inner PWI at:  0.2546540435393071\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3228929814388539\n",
            "New General Corpus set. Inner PWI at:  0.27959623056835714\n",
            "New General Corpus set. Inner PWI at:  0.2416197343163592\n",
            "New General Corpus set. Inner PWI at:  0.2373971614912044\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.29688341996037837\n",
            "New General Corpus set. Inner PWI at:  0.28533099155604147\n",
            "New General Corpus set. Inner PWI at:  0.28469867462850446\n",
            "New General Corpus set. Inner PWI at:  0.24125053044880346\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.325477569430252\n",
            "New General Corpus set. Inner PWI at:  0.2970176915302869\n",
            "New General Corpus set. Inner PWI at:  0.28960322683411943\n",
            "New General Corpus set. Inner PWI at:  0.2639615563131722\n",
            "New General Corpus set. Inner PWI at:  0.2476750771049592\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3205043547903813\n",
            "New General Corpus set. Inner PWI at:  0.2997717529079307\n",
            "New General Corpus set. Inner PWI at:  0.2159432397872488\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.24818013853450302\n",
            "New General Corpus set. Inner PWI at:  0.21274687875266288\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2696877633312279\n",
            "New General Corpus set. Inner PWI at:  0.26716994095237384\n",
            "New General Corpus set. Inner PWI at:  0.2455083849147978\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2631332558175143\n",
            "New General Corpus set. Inner PWI at:  0.26090105648174566\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3481604067023812\n",
            "New General Corpus set. Inner PWI at:  0.3245110686577171\n",
            "New General Corpus set. Inner PWI at:  0.3204664663306036\n",
            "New General Corpus set. Inner PWI at:  0.2813559158272133\n",
            "New General Corpus set. Inner PWI at:  0.260422860241902\n",
            "New General Corpus set. Inner PWI at:  0.24744275977403274\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3355074509237122\n",
            "New General Corpus set. Inner PWI at:  0.24327121394434228\n",
            "New General Corpus set. Inner PWI at:  0.24194892743152585\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2733056558121857\n",
            "New General Corpus set. Inner PWI at:  0.2503371606167626\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.2561029533744516\n",
            "New General Corpus set. Inner PWI at:  0.2509596209392646\n",
            "Refitting a batch of size  500\n",
            "New General Corpus set. Inner PWI at:  0.3961161899128186\n",
            "New General Corpus set. Inner PWI at:  0.2898420667881756\n",
            "New General Corpus set. Inner PWI at:  0.2878857663780407\n",
            "New General Corpus set. Inner PWI at:  0.2657646301391949\n",
            "New General Corpus set. Inner PWI at:  0.2638533435048567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ROC-AUC  Precision    Recall  F1-Score  Accuracy\n",
              "2019-06-01  0.457084   0.456413  0.457084  0.454986  0.457084\n",
              "2019-07-01  0.468661   0.419466  0.468661  0.372892  0.468661\n",
              "2019-08-01  0.497516   0.497456  0.497516  0.494566  0.497516\n",
              "2019-09-01  0.484138   0.481166  0.484138  0.462951  0.484138\n",
              "2019-10-01  0.464189   0.462918  0.464189  0.459558  0.464189\n",
              "2019-11-01  0.514706   0.516454  0.514706  0.501462  0.514706\n",
              "2019-12-01  0.510691   0.510740  0.510691  0.510134  0.510691\n",
              "2020-01-01  0.483983   0.483466  0.483983  0.479915  0.483983\n",
              "2020-02-01  0.478134   0.476703  0.478134  0.469997  0.478134\n",
              "2020-03-01  0.449088   0.447758  0.449088  0.445559  0.449088\n",
              "2020-04-01  0.506809   0.521861  0.506809  0.356632  0.421264\n",
              "2020-05-01  0.512325   0.512680  0.512325  0.512115  0.542857\n",
              "2020-06-01  0.492336   0.405503  0.492336  0.424106  0.723587"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b92637c5-a4e5-4cf3-a06a-d4ff09eeb364\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROC-AUC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-06-01</th>\n",
              "      <td>0.457084</td>\n",
              "      <td>0.456413</td>\n",
              "      <td>0.457084</td>\n",
              "      <td>0.454986</td>\n",
              "      <td>0.457084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01</th>\n",
              "      <td>0.468661</td>\n",
              "      <td>0.419466</td>\n",
              "      <td>0.468661</td>\n",
              "      <td>0.372892</td>\n",
              "      <td>0.468661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>0.497516</td>\n",
              "      <td>0.497456</td>\n",
              "      <td>0.497516</td>\n",
              "      <td>0.494566</td>\n",
              "      <td>0.497516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-01</th>\n",
              "      <td>0.484138</td>\n",
              "      <td>0.481166</td>\n",
              "      <td>0.484138</td>\n",
              "      <td>0.462951</td>\n",
              "      <td>0.484138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-01</th>\n",
              "      <td>0.464189</td>\n",
              "      <td>0.462918</td>\n",
              "      <td>0.464189</td>\n",
              "      <td>0.459558</td>\n",
              "      <td>0.464189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-01</th>\n",
              "      <td>0.514706</td>\n",
              "      <td>0.516454</td>\n",
              "      <td>0.514706</td>\n",
              "      <td>0.501462</td>\n",
              "      <td>0.514706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-01</th>\n",
              "      <td>0.510691</td>\n",
              "      <td>0.510740</td>\n",
              "      <td>0.510691</td>\n",
              "      <td>0.510134</td>\n",
              "      <td>0.510691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-01</th>\n",
              "      <td>0.483983</td>\n",
              "      <td>0.483466</td>\n",
              "      <td>0.483983</td>\n",
              "      <td>0.479915</td>\n",
              "      <td>0.483983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01</th>\n",
              "      <td>0.478134</td>\n",
              "      <td>0.476703</td>\n",
              "      <td>0.478134</td>\n",
              "      <td>0.469997</td>\n",
              "      <td>0.478134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01</th>\n",
              "      <td>0.449088</td>\n",
              "      <td>0.447758</td>\n",
              "      <td>0.449088</td>\n",
              "      <td>0.445559</td>\n",
              "      <td>0.449088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-01</th>\n",
              "      <td>0.506809</td>\n",
              "      <td>0.521861</td>\n",
              "      <td>0.506809</td>\n",
              "      <td>0.356632</td>\n",
              "      <td>0.421264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-01</th>\n",
              "      <td>0.512325</td>\n",
              "      <td>0.512680</td>\n",
              "      <td>0.512325</td>\n",
              "      <td>0.512115</td>\n",
              "      <td>0.542857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-01</th>\n",
              "      <td>0.492336</td>\n",
              "      <td>0.405503</td>\n",
              "      <td>0.492336</td>\n",
              "      <td>0.424106</td>\n",
              "      <td>0.723587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b92637c5-a4e5-4cf3-a06a-d4ff09eeb364')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b92637c5-a4e5-4cf3-a06a-d4ff09eeb364 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b92637c5-a4e5-4cf3-a06a-d4ff09eeb364');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 1000"
      ],
      "metadata": {
        "id": "YyGDkUUPyGKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact = Artifact(training_data, model, 1000)\n",
        "test_data = timeSampledDF[test].reset_index(drop=True)\n",
        "fullPred = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  fullPred.append(artifact.predict(test_data.loc[i, 'Text']))\n",
        "  artifact.add_data(test_data.loc[i, 'Text'], test_data.loc[i, 'Abgelehnt'])\n",
        "\n",
        "results = timeSampledDF[test]\n",
        "results['y_pred'] = fullPred\n",
        "testMonthly(results, results.Abgelehnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3mEXm8ajyFtz",
        "outputId": "f98d5838-5853-47ea-82ac-7c418e5d50b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3379944452982139\n",
            "New General Corpus set. Inner PWI at:  0.30337354094086505\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3588321961383542\n",
            "New General Corpus set. Inner PWI at:  0.31796845670202906\n",
            "New General Corpus set. Inner PWI at:  0.28366835644080957\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3650209503184012\n",
            "New General Corpus set. Inner PWI at:  0.36355649587766364\n",
            "New General Corpus set. Inner PWI at:  0.30328335288270286\n",
            "New General Corpus set. Inner PWI at:  0.2863871869603261\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.2998526940867459\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3045299741803459\n",
            "New General Corpus set. Inner PWI at:  0.3013323434885485\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.287017415938112\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.30618224537369887\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3085427470115556\n",
            "New General Corpus set. Inner PWI at:  0.2930938122075943\n",
            "New General Corpus set. Inner PWI at:  0.28719842612614316\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3362106831524089\n",
            "New General Corpus set. Inner PWI at:  0.3317608345287187\n",
            "New General Corpus set. Inner PWI at:  0.31105430291460695\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3655197643252686\n",
            "New General Corpus set. Inner PWI at:  0.3503926362420067\n",
            "New General Corpus set. Inner PWI at:  0.34392015988114005\n",
            "New General Corpus set. Inner PWI at:  0.3105110236140875\n",
            "New General Corpus set. Inner PWI at:  0.29789545992993965\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.34844162217077945\n",
            "New General Corpus set. Inner PWI at:  0.3378642752528828\n",
            "New General Corpus set. Inner PWI at:  0.33639644518755585\n",
            "New General Corpus set. Inner PWI at:  0.3232210660775997\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3381544826641428\n",
            "New General Corpus set. Inner PWI at:  0.32016822209591944\n",
            "New General Corpus set. Inner PWI at:  0.31373536859810097\n",
            "New General Corpus set. Inner PWI at:  0.29981559929444057\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.3371285288953566\n",
            "New General Corpus set. Inner PWI at:  0.30460458939602963\n",
            "New General Corpus set. Inner PWI at:  0.26658865974948326\n",
            "Refitting a batch of size  1000\n",
            "New General Corpus set. Inner PWI at:  0.30661823274176175\n",
            "New General Corpus set. Inner PWI at:  0.2922551943313704\n",
            "Refitting a batch of size  3553\n",
            "New General Corpus set. Inner PWI at:  0.3505614566687916\n",
            "New General Corpus set. Inner PWI at:  0.316098171849488\n",
            "New General Corpus set. Inner PWI at:  0.31008004557093977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ROC-AUC  Precision    Recall  F1-Score  Accuracy\n",
              "2019-06-01  0.502068   0.514051  0.502068  0.367142  0.502068\n",
              "2019-07-01  0.502374   0.514357  0.502374  0.371163  0.502374\n",
              "2019-08-01  0.499379   0.499228  0.499379  0.473644  0.499379\n",
              "2019-09-01  0.505517   0.508168  0.505517  0.461860  0.505517\n",
              "2019-10-01  0.495946   0.477508  0.495946  0.366018  0.495946\n",
              "2019-11-01  0.476716   0.476702  0.476716  0.476637  0.476716\n",
              "2019-12-01  0.505757   0.532212  0.505757  0.378058  0.505757\n",
              "2020-01-01  0.485376   0.479560  0.485376  0.445964  0.485376\n",
              "2020-02-01  0.507289   0.511794  0.507289  0.455264  0.507289\n",
              "2020-03-01  0.531915   0.538262  0.531915  0.511662  0.531915\n",
              "2020-04-01  0.534813   0.538733  0.534813  0.491880  0.495486\n",
              "2020-05-01  0.539167   0.544451  0.539167  0.487706  0.491837\n",
              "2020-06-01  0.516394   0.514674  0.516394  0.513658  0.599509"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65a4a19f-f17d-469d-ae3e-25d0b3ff1f26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROC-AUC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-06-01</th>\n",
              "      <td>0.502068</td>\n",
              "      <td>0.514051</td>\n",
              "      <td>0.502068</td>\n",
              "      <td>0.367142</td>\n",
              "      <td>0.502068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-01</th>\n",
              "      <td>0.502374</td>\n",
              "      <td>0.514357</td>\n",
              "      <td>0.502374</td>\n",
              "      <td>0.371163</td>\n",
              "      <td>0.502374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-01</th>\n",
              "      <td>0.499379</td>\n",
              "      <td>0.499228</td>\n",
              "      <td>0.499379</td>\n",
              "      <td>0.473644</td>\n",
              "      <td>0.499379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-01</th>\n",
              "      <td>0.505517</td>\n",
              "      <td>0.508168</td>\n",
              "      <td>0.505517</td>\n",
              "      <td>0.461860</td>\n",
              "      <td>0.505517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-01</th>\n",
              "      <td>0.495946</td>\n",
              "      <td>0.477508</td>\n",
              "      <td>0.495946</td>\n",
              "      <td>0.366018</td>\n",
              "      <td>0.495946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-01</th>\n",
              "      <td>0.476716</td>\n",
              "      <td>0.476702</td>\n",
              "      <td>0.476716</td>\n",
              "      <td>0.476637</td>\n",
              "      <td>0.476716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-01</th>\n",
              "      <td>0.505757</td>\n",
              "      <td>0.532212</td>\n",
              "      <td>0.505757</td>\n",
              "      <td>0.378058</td>\n",
              "      <td>0.505757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-01</th>\n",
              "      <td>0.485376</td>\n",
              "      <td>0.479560</td>\n",
              "      <td>0.485376</td>\n",
              "      <td>0.445964</td>\n",
              "      <td>0.485376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-01</th>\n",
              "      <td>0.507289</td>\n",
              "      <td>0.511794</td>\n",
              "      <td>0.507289</td>\n",
              "      <td>0.455264</td>\n",
              "      <td>0.507289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01</th>\n",
              "      <td>0.531915</td>\n",
              "      <td>0.538262</td>\n",
              "      <td>0.531915</td>\n",
              "      <td>0.511662</td>\n",
              "      <td>0.531915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-01</th>\n",
              "      <td>0.534813</td>\n",
              "      <td>0.538733</td>\n",
              "      <td>0.534813</td>\n",
              "      <td>0.491880</td>\n",
              "      <td>0.495486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-01</th>\n",
              "      <td>0.539167</td>\n",
              "      <td>0.544451</td>\n",
              "      <td>0.539167</td>\n",
              "      <td>0.487706</td>\n",
              "      <td>0.491837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-06-01</th>\n",
              "      <td>0.516394</td>\n",
              "      <td>0.514674</td>\n",
              "      <td>0.516394</td>\n",
              "      <td>0.513658</td>\n",
              "      <td>0.599509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65a4a19f-f17d-469d-ae3e-25d0b3ff1f26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65a4a19f-f17d-469d-ae3e-25d0b3ff1f26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65a4a19f-f17d-469d-ae3e-25d0b3ff1f26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "7cbMeBEcRjZz",
        "y_nYzFCqIBsI"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}